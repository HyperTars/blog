[{"content":"Redis Architecture Redis 分布式 - Sentinel 实现：Codis\n组件 dashboard\n中心管理节点 元信息由外部存储（Zookeeper etc）提供一致性保障 一个 dashboard 管理一个集群 proxy\n接入层，与 client 直接交互 Golang 实现，支持主流命令 路由信息由 dashboard 推送 server\n对于开源 Redis 进行扩展，支持 slot 操作，迁移 slot 时，由主线程进行异步迁移 扩展性 slot 数量为 1024，shard 数量大几百后容易出现数据分布不均匀 数据迁移由 dashboard 主导，扩缩容比较强依赖 dashboard 不支持多机房 可用性 无 Proxy HA Server HA 由 redis-sentinel 负责，相对来讲引入了一些运维复杂性 无机房级别容灾 稳定性 扩容时数据迁移：在主线程进行迁移 AOF：主线程同步刷盘，不支持异步 弱网鲁棒性：较容易触发全量同步，影响稳定性 RTO：Proxy，无副本补齐功能 Redis 分布式 - Redis Cluster 组件 Server\n社区原生 每个 redis 实例都有全局拓扑信息 redis 实例之间通过 Gossip 协议网状互联同步 slot 信息 Proxy\n可选 redis-proxy 支持主流命令，社区活跃度低 可选 twemproxy 支持主流命令，原生 twemproxy 不支持 redis-cluster 扩展性 slot 数量 16384，key 粒度迁移步骤繁琐 不支持多机房，需要依赖外围 rcmirror 等脚本控制 规模较小，容易产生 gossip 网络风暴，内部使用限制在 150 分片 可用性 HA 自治：Gossip + Vote -\u0026gt; Slave 自己提主（半数以上投票判定 master 挂掉、提主） 无机房级别容灾 稳定性 扩容时数据迁移：在主线程进行迁移 AOF：不支持异步 弱网鲁棒性：较容易触发全量同步，影响稳定性 RTO：Proxy，无副本补齐功能 问题 规模化：gossip 风暴导致网络流量过大，导致网络延迟，只能将集群控制在 300 个实例（150 分片） 一致性：双机房同步依赖外部组件 rcmirror，无法做到幂等同步，从而导致数据可能最终无法一致 容灾：双机房容灾场景下需要全量同步 Redis 分布式 - 多活中心化 组件 configserver cluster\n统一管理集群，上线、扩容、探活、主从切换 如果一个 configserver 挂掉，redis 集群会被其他 confiserver 接管 configserver 将元数据写入 ETCD（raft） 使用 AOF binlog 做多机房同步，减少网络和 CPU 开销 使用 AsyncMigrate 降低 redis 数据迁移阻塞 proxy cluster\n使用 consul 做服务发现，提供具体的 proxy 供 Client SDK 调用查询 请求 configserver cluster 获得元信息 请求 redis cluster 获得数据 redis-server cluster\n每个 cluster 由两组 master-slave 组成 configserver 控制 redis-server 创建、同步等操作及元信息 异步迁移 扩展性 slot 数量 16384，均匀分布，迁移由 configserver 主导，支持多机房 AOF 增量复制（主从建立连接时 master 读取 AOF 避免全量同步） 异步写盘 slave 收到写命令返回 removed 主，proxy 解析 removed 并重试 异步子线程迁移 slot，状态在主从保持一致 可用性 cnfigserver HA：ETCD 的 RPC + Lock proxy HA：Consul redis-server HA：configserver 控制 支持机房级别容灾 稳定性 扩缩容时 redis 在子线程迁移 redis 数据 configserver 自动进行 redis-server 副本保持，补从 configserver 自动进行 proxy 副本保持 redis-server 支持 AOF 增量复制，尽量避免全量同步 改进措施 可扩展：支持更多分配 可靠性：机房切换增量同步；region 内主从副本切换后增量同步 稳定性：异步删除、异步迁移 一致性：基于 redis 自身同步没有一致性问题 Redis 分布式 - 云原生 解决问题\nredis 最大的难点在于规模化 规模化后如何提供可靠的服务，如何保证运维压力可控：规模化的问题通过标准化解决，通过云原生将部署标准化。 平滑升级、故障自愈、资源隔离问题 云原生理论基础\n不可变基础设施（通过容器镜像实现，应用的基础设施是不可变的，是一个自包含、自描述可以完全在不同环境中迁移的东西） 云应用编排理论（全部交由 K8s 管理，部署在 pod） Redis 分布式架构总结对比 中心化 Cluster Sentinel 集群架构 中心化，configserver 统一管理集群 去中心化，gossip 形成网状集群 中心化，dashboard 统一管理集群 redis-server 1. AOF 增量复制（主从建连时 master 读取 AOF 避免全量同步）\n2. 异步写盘\n3. 迁移时保持主从状态，子线程异步迁移 slot\n4. 容灾场景增量复制 proxy 1. 主动连接 configserver 拉拓扑信息\n2. client 通过 consul 发现 proxy proxy 连接 redis 拉取拓扑信息 1. dashboard 向 proxy 推送拓扑信息\n2.client 连接 zookeeper 获取所有 proxy configserver/dashboard 1. 一个 configserver 管理多个 redis 集群，如果挂掉，redis 集群会被其他 configserver 接管\n2. configserver 将元数据写入 ETCD 1. 无 configserver 或 dashboard\n2. 每个 redis 实例都有全局拓扑信息\n3. redis 实例之间通过 gossip 互相同步 slot 信息 1. 一个 dashboard 管理一个 redis 集群\n2. dashboard 将元数据写入 zookeeper 扩展性 1. slot 数量为 16384，数据均匀分布\n2. slot 迁移由 configserver 主导\n3. 支持多机房 1. 不支持多机房\n2. slot 迁移需要由外部脚本控制，key 粒度迁移，步骤繁琐 1. slot 数量为 1024，shard 数量大几百后容易出现数据分布不均匀\n2. 数据迁移由 dashboard 主导，扩缩容比较强依赖 dashboard\n3. 不支持多机房 可用性 1. 支持 Proxy HA\n2. configserver 控制 redis-server HA\n3. 支持机房级别容灾 1. 集群自带 HA，一个 master 挂掉时，集群半数以上 master 投票挂掉则判定指定 master 挂掉，slave 发起选举，半数以上 master 同意，则 slave 提主成功\n2. 无机房级别容灾 1. 无 Proxy HA\n2. redis-server HA 由 redis-sentinel 负责，引入一定运维复杂性\n3. 无机房级别容灾 稳定性 1. 扩缩容时 redis 在子线程进行数据迁移\n2. configserver 自动进行 redis-server 副本保持，补从\n3. configserver 自动进行 proxy 副本保持\n4. redis-server 支持 AOF 增量复制，尽量避免全量同步 1. 扩缩容时 redis 在主线程进行数据迁移\n2. AOF：主线程同步刷盘\n3. 弱网鲁棒性：与开源一致，较容易触发全量同步，影响稳定性\n4. RTO：无 proxy，副本补齐功能 ","permalink":"https://blog.hypertars.com/posts/developer/infrastructure/redis/","summary":"Redis Architecture Redis 分布式 - Sentinel 实现：Codis 组件 dashboard 中心管理节点 元信息由外部存储（Zookeeper etc）提供一致性保障 一个 dashboard 管理一个集群 proxy 接入层，与 client","title":"Redis"},{"content":"分布式锁常见应用场景 防止缓存击穿\nRedis 的 Key 失效后，在查数据库前加一个分布式锁，查出来后把数据放到 Redis，保证大流量请求进来时，不会出现缓存击穿，只会有一个请求打到数据库。 保证接口幂等\n表单重复提交后没处理完，再次提交相当于提交了两份。提交后添加分布式锁，第一次提交的时候会锁住，第二次提交发现有锁，就不会继续执行业务逻辑。 任务调度\n分布式定时任务。可以通过分布式锁保证集群只执行一次任务。 分布式锁特征 高性能：分布式锁加锁和解锁不影响主业务逻辑，如果每次加锁和解锁都要花费几百 ms 是不能容忍的 可重入：对于同一个线程，要能重复加锁和解锁（可重入的条件是持有锁的线程是当前请求的线程），而不是阻塞等待卡死，重入几次就要释放几次。 互斥性 防死锁：锁不能及时释放会造成死锁，比如加锁了因为服务宕机了没有释放锁，可以给每把锁添加过期时间，这样即时服务意外宕机，等待一段时间后就会自动释放，避免死锁发生。\n实现分布式锁的常见方式 MySQL 实现分布式锁 实现原理 通过 MySQL 唯一索引实现，本质上是对于同一条数据的竞争操作，保证多点系统里同时只有一个执行线程进行处理（只能打到主库）。\n基于唯一索引实现（insert） 获取锁时在数据库中 insert 数据，插入成功即视为成功，互斥体现在插入重复数据会报错唯一 key 异常；释放时删除数据 缺点：强依赖数据库的可用性；没有超时保护，释放失败其他线程无法再次获取；并发压力 基于排它锁实现（for update） select .. for update 对查询过程中的数据表增加排它锁，其他线程无法再次增加排它锁，认为获得排它锁的线程获得分布式锁；释放时 commit，提交事务实现 缺点：强依赖数据库的可用性；排它锁占用连接，产生连接爆满问题，for update 连接阻塞；并发压力 需要考虑的设计细节\n分布式锁的表如何设计？唯一的锁 key 如何设计？可重入如何设计？ 可重入的关键在于需要一个字段存储重入次数，还要记住是哪个机器、哪个线程重入的 1 2 3 4 5 6 7 8 9 10 11 DROP TABLE IF EXISTS `common_lock`; CREATE TABLE `common_lock` ( `id` uint64 NOT NULL AUTO_INCREMENT, `lock_key` varchar(100) NOT NULL, `thread_id` int NOT NULL, `entry_count` int NOT NULL, `host_ip` varchar(30) NOT NULL, `lock_time` timestamp NOT NULL, PRIMARY KEY (`id`), UNIQUE KEY `lock_key` (`lock_key`) USING BTREE ) ENGINE = InnoDB DEFAULT CHARSET=utf8mb4; 如何判断重入逻辑？ 判断有没有锁，有锁再继续判断是不是自己加的锁，如果是自己的锁就更新 entry_count +1 抢锁失败后如何重试？ 死循环一直重试、重试到一定次数、重试一定时间，若持续加锁失败则退出 如何安全地释放锁？ 不可以直接删除 key，因为有重入情况。需要先判断重入次数，若大于 1 则减 1，若等于 1 才删除 防死锁设计？加锁成功，释放前系统宕机（需要考虑过期淘汰，防止无限膨胀） 起定时任务定时检查由于意外宕机或其他原因导致锁一直没释放的数据，若超过一定时间没释放，则自动释放 解决方案是记录加锁时间，定时扫描超出 n 秒还未释放的锁的数据，将其删除释放 删除超过 10 分钟没释放的锁 1 SELECT * FROM `common_lock` WHERE `lock_time` \u0026lt; DATE_SUB(NOW(), INTERVAL 10 MINUTE); follow up：如果流程很耗时，执行结束前定时任务扫描认为锁超时提前释放，其他客户端成功上锁？ 单独起个线程进行定时续期（WatchDog） 优缺点 优点\n不需要引入其他中间件 缺点\n性能低、并发低 强依赖 MySQL，MySQL 不能出现单点故障 支持的锁种类有限而且使用不灵活，实现非公平锁容易，要实现公平锁需要模拟队列，实现读写锁则更为麻烦 Redis 实现分布式锁 实现原理 单节点分布式锁 核心是单机单线程，内存速度快。分布式 Redis Cluster 也会有锁不住的问题。主要基于 setnx(SET key ramdom_value NX PX time)，查看是否有响应键值对存在，若没有或过期则设置此键值对，若有则不会获得锁。 一般用 lua 脚本释放锁，保证原子性；先判断 redis 此时随机值 random_value 是否是之前客户端设置的，如果是则 del，否则不处理。 随机值：超时后被其他线程抢的锁不可释放 缺点：主从切换时多客户端认为自己有锁，就锁不住了。 RedLock（redis cluster） 核心针对高可用问题，解决单集群 Redis 宕机导致服务不可用以及集群 master 宕机，slave 节点尚未收到同步，导致多 client 获取到锁。 N 个单独部署的 Redis 集群，每个集群独立存在，无主从复制 获取锁的操作有一个超时时间，远小于锁的有效时间；向某个 redis 节点获取锁失败后，应立即尝试下一个 redis 节点。 计算整个获取锁的过程总共消耗了多长时间，如果客户端从大多数 redis 节点成功获取到了锁，并且总耗时没有超过锁的有效时间，那么才认为获取锁成功，否则认为获取锁失败。 锁的有效时间应当减去获取锁的消耗时间 如果获取锁失败了，客户端应该立即向所有 redis 节点发起释放锁操作（lua） 缺点：时钟漂移问题 Redisson（Java 客户端） 核心是使用 WatchDog 解决锁续期问题，屏蔽实现细节及实现可重入，等待申请锁资源的进程减少了无效的锁申请，提升资源利用率 使用 lua 脚本加锁，hash 数据类型的 key 包括当前线程信息、客户端信息，value 用于可重入计数；使用阻塞的方式减少锁的申请 使用 watchdog 每隔一定时间检查锁是否存在，存在就续期 使用 lua 脚本解锁，不存在的话用 publish 发布释放锁的消息；存在则用 hincrby 可重入次数 -1，若重入次数大于 0 则刷新续期，否则删除并释放；若不被当前线程持有则返回空 缺点：主从部署或哨兵模式时，master 在加锁后宕机，并且数据未同步到 slave，会导致多客户端同时获取锁 实现 Redis 分布式锁的关键点\n原子性 集群内把锁存起来，使用 SETNX 命令并带上过期时间 过期时间 有效避免死锁 锁续期 另开一个线程，专门用于锁续期，上锁的时候起线程进行死循环续期（比如 3s 的锁，每一段过了第一个 1s 就续 3s） 正确释放锁（不可以提前释放、不可以释放别人的锁） 任务执行完成前不能释放。解锁前要先判断这个 key 的 value 是否是自己加的。value 不能仅仅是线程，分布式可能重复，可以是随机数或机器 IP。即 redis 虽然单线程，但是客户端可能是多线程的。 释放锁时调用 Redis GET 和 DEL 操作是非原子的，所以尽量使用 EVAL (Lua 脚本)，将 GET 和 DEL 包装到一条命令给 Redis 执行 释放锁时先判断锁次数是不是大于 1，是的话就是有锁重入，不能删除，需要减 1，如果次数等于 1 了，也就是没有重入锁了，那就直接删除 WatchDog 实现原理 核心工作流程是定时检测锁是否还存在，还存在的话检查是否快到期，快到期则重新续期，这样防止如果业务代码还没执行完，锁却过期了所带来的的线程不安全问题。。 加锁时开启 WatchDog，删除锁时取消 优缺点 优点\n性能高，对业务系统影响较小 Redisson 客户端类库将所的所有用法都封装了（可重入锁、读写锁、公平锁） 1 2 3 4 # 采用 hash 结构存储 myLock: { [uuid:threadID]:锁次数 } 缺点\n只能保证 AP，对数据一致性要求高的系统不适合（不能真正意义上的一致性地锁住） 分布式 Redis 锁不住？ 先说结论：redis 多机房同步是最终一致的，如果有分布式锁的需求，会有锁不上的情况。redis 锁只能作为弱校验，不能作为强依赖。有强一致锁需求的使用基于 Raft、Paxos 等强一致性（共识算法）的锁更为可靠。\n当 redis 分布式架构的主机房不可用时，系统自动切换到副节点，即 failover 过程。由于主从非同步，在 failover 过程中会导致锁被抢。\nmaster 拿到锁 A slave1-master 同步开启 master 宕机，failover 开启 slave1-master 同步未完成 slave1 被选举为 master，锁 A 丢失，可被抢 使用 RedLock 红锁也锁不住？\nFull GC 恢复后冲突问题 严重依赖时钟系统 效率面前 RedLock 太重 正确性极高场景下 RedLock 不能保证正确性 https://cloud.tencent.com/developer/article/1608807 Zookeeper 实现分布式锁 实现原理 Zookeeper 实现分布式锁的核心原理是临时有序节点，通过判断自己是否是有序节点中序号最小的一个确定是否获得锁，通过删除节点释放锁。ZK 的节点通过 session 心跳来续期。若果客户端 A 创建了一个节点，那么客户端 A 会和 ZK 服务器创建一个 session，通过该 session 的心跳维持连接。如果 ZK 服务器长时间没有收到这个 session 心跳，就认为这个 session 过期了，也会把对应的节点删除。\n对比 Redis 作为分布式锁的时候，为防止宕机死锁需要添加过期时间，为防止提前过期还要开启 WatchDog 续期，ZK 只需要利用临时节点即可。 临时节点类型的最大特性是：当客户端宕机后，临时节点随之消亡。 排他锁（写锁 / 独占锁）\n只允许单事务对指定对象进行读写操作，其他任何事务不能对这个数据对象做任何操作 核心：保证当前有且仅有一个事务获得锁，且锁释放后所有正在等待获取锁的事务都能被通知到 定义锁：通过 ZK 上的临时数据节点来表示一个锁 获取锁：利用 ZK 的同级节点唯一性特点，在需要获取锁时，所有的客户端试图通过调用 create() 在节点下创建临时子节点，最终只有一个客户端能成功，那么此客户端就获得了分布式锁。 阻塞等待：同时，没有获取到锁的客户端阻塞等待，可以在节点上注册一个子节点变更的 watcher 监听事件，以便重新争取获得锁。如果上一个节点释放了锁，那就立即得到通知，然后自己上锁。 释放锁：当客户端抢到锁后就给这个客户端分配一个临时节点，只要没释放就一直持有。当释放主动锁后（正常情况）或服务意外宕机（异常情况）时，临时节点就会被删除，其他客户端就可以重新获取锁。 缺点：并发高容易引起 Zookeeper 的羊群效应（aka 惊群效应 watcher 通知的客户端很多，引起 ZK 性能下降） 解决：客户端只监控比自己小的那个节点，如果自己的序号最小，则获取锁 共享锁（读锁）\n当前事务对指定对象进行读操作，其他事务也只能堆这个数据对象加共享锁，直到该对象上的所有共享锁都被释放 定义锁：通过 ZK 上的临时数据节点来表示一个锁，类似于 /lockpath/[hostname]-请求类型-序号 的临时顺序节点 获取锁：客户端调用 create() 方法创建表示锁的临时顺序节点 读请求：/lockpath/[hostname]-R-序号 写请求：/lockpath/[hostname]-W-序号 判断读写顺序： 创建节点后，获取 /lockpath 节点下所有子节点并注册该节点的子节点变更 watcher 监听 确定自己的节点在所有节点中的顺序 判断 对于读请求：如果没有比自己序号更小的节点，或者序号比自己更小的节点均为读请求，则可认为获得锁，进行读取操作 对于写请求：当且仅当没有比自己序号更小的节点时可进行写操作 接到 watcher 监听事件之后重复上述步骤 释放锁：与排他锁一致（主动删除或宕机被动删除） Zookeeper 锁不住？ Zookeeper 的节点是通过 session 心跳来续期的，比如客户端 A 创建了节点，那么客户端 A 会和 ZK 创建一个 session，通过 session 的心跳来维持连接。 如果 ZK 服务器长时间没收到这个 session 的心跳就认为这个 session 过期了，也会把对应的节点删除。 如果发生了 Full GC，Stop The World 时间大于 session 心跳时间了，就有可能发生误删，或者因为网络抖动导致 session 过期，导致节点被删除，进而其他客户端可以加锁，此时会有两把锁同时执行。\nETCD 实现分布式锁 ETCD 是一个可靠的分布式锁，基于 Raft 算法保持一致性，主要用于共享配置和服务发现\nETCD 基本概念 Lease 机制\n租约机制（TTL），对 KV 设置租约，到期后 KV 失效，客户端可以主动发起续约 Revision 机制\n每个 key 带有一个 revision，ETCD 每执行一次事务对应的全局 revision 值 +1，因此每个 key 对应的 revision 属性都是全局唯一的。通过比较 revision 的大小可以知道进行写操作的顺序，避免惊群效应 Prefix 机制\n可以根据前缀获取该前缀下所有的 key 及对应属性（包括 key，value 及 revision） Watch 机制\n支持 watch 某个固定的 key，也支持 watch 前缀机制，当 watch 的 key 或前缀下发生变化时就会通知客户端 实现原理 ETCD V3 官方实现分布式锁，与 mutex 用法类似。和 Zookeeper 类似，但是实现的机制各有不同。\nSource Code\n1 2 3 4 5 6 // session 基于 lease 机制实现，默认 60s 过期 func NewMutex(s *Session, pfx string) *Mutex // 阻塞直到获取锁，也可以通过 ctx 取消获取锁 func (m *Mutex) Lock(ctx context.Context) error // 解锁 func (m *Mutex) Unlock(ctx context.Context) error 创建租约：假设以 /lock 为前缀，客户端 a 对应的 key 为 /lock/uuid_a，客户端 b 对应的 key 为 /lock/uuid_b，并分别创建租约 客户端写入 key：客户端 a 和 b 分别执行 put 事务操作，得到不同 revision，假设分别为 1 和 2 判断是否得到锁：客户端读取 /lock 前缀下的所有 KV 列表，判断列表中最小的 revision 是否和自己的 revision 相同，如果相同则获取锁 未得到锁监听：未得到锁则监听比自己 revision 小的 key 的删除事件，监听失败则删除自己的 key，防止同一个 session 后序获取锁时出现死锁问题，成功则获取锁。 ","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/lock/","summary":"分布式锁常见应用场景 防止缓存击穿 Redis 的 Key 失效后，在查数据库前加一个分布式锁，查出来后把数据放到 Redis，保证大流量请求进来时，不会出现缓存击","title":"分布式锁"},{"content":"基本特性 列式向量 OLAP 数据库 (Column Oriented OLAP) 向量化查询 (Vectorized Query Execution) MPP, Shared Nothing 架构 支持 SQL + extensions 实时查询 (亚秒级) 性能对比 ClickHouse 最显著的特点就是数据分析查询场景下速度快。 单机, 初次查询 (Cold Cache) 场景下, 对各类聚合分析查询 1 亿数据, 比 Hive 快 107 倍, 比 MySQL 快 360 倍。 10 亿行数据, 比 Vertica 快 2.14 倍, 比 Greenplum 快 7.07 倍 适用场景 适合的场景: ClickHouse 适合于对结构化(structured)，不可变的(immutable)数据进行聚合分析 Click Streams Web Analytics Montioring Streams 但由于 ClickHouse 主要是为 OLAP 场景设计的数据库，对于 OLTP 的场景支持较差 缺少对事务的支持 不能高效地进行已写入数据的删除和更新 单点查询的性能并不高 设计原则 Keep in mind low-level details when designing your system. Design based on hardware capabilities. Choose data structures and abstractions based on the needs of the task. Provide specializations for special cases. Try new, “best” algorithms, that you read about yesterday. Choose an algorithm in runtime based on statistics. 具体实现 架构 Massive Parallel Processing (MPP)\nShared Nothing\n在 ClickHouse 中, 数据的存储和检索采用 Shared Nothing 设计, 即数据分布在多个节点上且各个节点所拥有的子数据集互不重叠, 所有的通信都是通过网络进行的。每个节点只负责对自身拥有的数据进行存储和分析计算。\n存储 MergeTree\nMergeTree（合并树）表引擎是 ClickHouse 提供的默认存储引擎。MergeTree 支持数据按主键、数据分区、数据副本以及数据采样等特性。 了解MergeTree三个问题\nMergeTree 有哪些文件？ MergeTree 数据如何分布？ MergeTree 如何创建和使用索引？ 文件构成 假设我们通过下面的SQL创建一个表 default.mt，并写入一些数据。它包含3列 a, b, c。我们以 a 作为分区键(partition key)，以b作为排序键(sorting key)，以c作为索引键(index key)。其中还包含了如“minmax”，“granularity”等等设置，在后面会进行介绍。 1 2 3 4 5 6 7 8 9 10 11 12 13 CREATE TABLE default.mt ( `a` Int32, `b` Int32, `c` Int32, INDEX `idx_c` (c) TYPE minmax GRANULARITY 1 ) ENGINE = MergeTree PARTITION BY a ORDER BY b SETTINGS index_granularity=3; //8192 INSERT INTO default.mt(a,b,c) VALUES(1,1,1); INSERT INTO default.mt(a,b,c) VALUES(5,2,2),(5,3,3); INSERT INTO default.mt(a,b,c) VALUES(3,10,4),(3,9,5),(3,8,6),(3,7,7),(3,6,8),(3,5,9),(3,4,10); 上面的三次 INSERT 操作，会在文件系统中生成三个文件目录。每个目录称为 datapart 1 2 ls ckdatas/data/default/mt/ 1_4_4_0 3_6_6_0 5_5_5_0 //每个目录代表一个datapart Datapart 目录的命名：Partition_StartBlockNum_StartBlockNum_MergeTreeLevel 第一段表示partition key的内容。刚才3次插入的数据中分别有 a 具有1,3,5这三个值，因此生成了 1_xxx, 3_xxx, 5_xxx 三个datapart。 查看其中一个partiton key为3的datapart（3_6_6_0） 的内容如下 1 2 3 4 5 6 7 ls ckdatas/data/default/mt/3_6_6_0/ a.bin a.mrk2 b.bin b.mrk2 c.bin c.mrk2 skp_idx_idx_c.idx skp_idx_idx_c.mrk2 primary.idx checksums.txt columns.txt count.txt partition.dat 其中每个文件的含义如下 *.bin：列数据文件，按主键排序(ORDER BY)，这里是按照字段 b 进行排序 *.mrk2：mark 文件，目的是快速定位 bin 文件数据位置 primay.idx：主键索引文件，目的是加速主键 b 查找 skp_idx_idx_c.*：字段 c 索引文件，目的是加速 c 的查找 数据分布 在刚才的插入过程中我们写入了 (3,10,4),(3,9,5),(3,8,6),(3,7,7),(3,6,8),(3,5,9),(3,4,10) 这些数据，因此在分区 3_6_6_0中 a.bin里的值都是3。\n当数据量较多时, 读取一个 *.bin 的 IO 成本太高, 因此, ClickHouse 把 bin 文件根据颗粒度 (granularity) 划分为多个颗粒 (granule), 每个 granule 单独压缩存储。前面在建表时设置了 SETTINGS index_granularity=3 表示每 3 行数据为一个 granule, 分区目前只有 7 条数据, 所以被划分成 3 个 granule\n为方便读取某个 granule, 使用 *.mrk 文件记录每个 granule 的 offset, 每个 granule 的 header 里会记录一些元信息, 用于读取解析。\n类似于 LSM Tree, ClickHouse 也会对生成的 datapart 进行后台的合并, 从而减少查询时的开销, 并对数据进行汇聚以获得更大压缩比。\nWAL 20.6版本以前 ClickHouse 每次进行 INSERT 操作都会创建至少一个 datapart。因此在频繁写入的情况下会产生大量小的 datapart，给文件系统以及 datapart 的合并造成负担。因此官方文档中建议每次以 Batch 的方式写入数据，每次插入间隔不少以1s。 20.6版本后，Clickhouse 引入了 Write-Ahead Log 机制，从而有效地解决了频繁写入的问题。与 LSM-Tree 的机制相似，Clickhouse 在内存中维护一个称为 In-memory datapart 的数据结构（类似 MemTable），并将插入的数据内容写到 wal.bin 文件中。wal.bin 里的数据 会定期进行合并，生成新的 datapart。 类似地，在查询数据时，需要同时检索 wal.bin 文件 Sparse Index 为了能快速的找到数据, 我们还需要有办法能快速定位到目标数据所在的 granules。在 ClickHouse 里有两种索引方式 Primary Index 主键索引, 可通过 Primary Key Expr 指定, 默认时 ORDER BY 字段。在前面的例子中设置了 ORDER BY b, 因此 ClickHouse 会按照 b 的值对数据进行排序, 并构建 primary.idx。其中每一项对值取每个 granule 中 b 的第一个值。 Skipping Index 普通列的索引。它的作用是对列中各个granule的数据信息进行聚合，从而能在查询时跳过（Skipping）不满足查询要求的granules，从而减少扫描的数据量，提高查询效率。 以建表例子中 INDEX idx_c(c) TYPE minmax GRANULARITY 1 为例。表示针对字段 c 创建一个 minmax 模式的 Skipping 索引。 GRANULARITY 是稀疏点选择上的 granule 颗粒度，GRANULARITY 1 表示每 1 个 granule 选取一个 由于它是minmax索引，顾名思义，skp_idx_idx_c.idx文件里的每一项记录了对应granules里面列c的最大值和最小值。 以下图为例，如果在进行 SELECT操作时指定了 c=6 的话，则可以通过 min_c 和 max_c 的值快速判断出第 1，3 granules里的不满足查询条件，这两个 granule 可以被直接跳过，而只遍历第二个granule里的数据。 如果定义为GRANULARITY 2 ，则 2 个 granule 选取一个，来计算 skipping index里的值。 除了 minmax类型以外，skipping index还支持以下的类型 set: 保存被索引列中各个granule里distinct的值。适合列中数据cardinality较小的场景 bloom_filter: 使用 bitmap 构建布隆过滤器。例如可以对 traceID, spanID 等数据范围较大其随机的列构建这样的索引。 ngrambf_v1, tokenbf_v1: 针对 string 类型的列，分别使用 n-gram 和 tokenization 的方式对文本内容构建布隆过滤器。适合进行长字符串的 startsWith, endsWith, in, like等查询场景。 查询 向量化执行模型 \u0026amp; SIMD 向量化执行模型（Vectorization Processing Model）是OLAP数据库中常用的执行模型（e.g. Presto, SQL Server, Oracle等）。它在执行流程上类似于一般的火山模型，区别在于在各个算子每次返回一批数据（Batch，例如上千行）给上游的算子。 这样可以让计算更多的停留在函数内，而不是频繁的交互切换，提高了CPU的流水线并行度，而且还可以使用SIMD指令来实现数据并行处理。 在ClickHouse对数据的处理中使用了很多SIMD指令以加速运算，例如 文本解析 数据过滤 [example] 解压缩数据块 字符串运算 定制化的算法 ClickHouse在工程实现上非常注重细节的优化。在算法的选择上遵循以下几个维度的考虑\n数据类型 数据大小 数据是否有序 数据的分布情况 Group By 大多数 OLAP 的查询场景都包含类似 Group by 的聚合分析。对于ClickHouse来说，这也是其着重进行了查询优化的地方。默认情况下 ClickHouse使用内存中的 hashMap 进行聚合。在目前的实现中，ClickHouse 针对不同的聚合数据类型有超过14种不同的实现。每种实现都力求是特定场景下的最优实现。根据数据类型 \u0026amp; 数据范围的不同，ClickHouse 会动态选择不同的 hashMap实现，例如\nHashMapWithSavedHash\n适合key是字符串的场景。由于字符串的比较操作较为耗时，ClickHouse在hashMap的key中同时保存string与string的数字hash值，这样就可以通过hash值的对比减少string不匹配时的字符串比较开销 FixedHashMap\n适合key是uint8或者uint16的场景。ClickHouse直接分配一个定长的数组作为hashtable。hash时直接将Key作为数组下标找到对应的Slot TwoLevelHashMap\n适合key的数据量较多的场景。随着数据量的增多，单个hashMap的规模也越来越大，其进行resize的成本也随之增加。因此,当单个hashMap超过一定的内存阈值以后，ClickHouse会将其中的每个key重新hash到256个bucket，每个bucket又是一个独立的 hashMap。在进行resize时，每个子hashMap互相独立，因此代价也更小。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // https://clickhouse.tech/codebrowser/html_report/ClickHouse/src/Interpreters/Aggregator.h.html // key的range较小时，直接使用定长数组作为hashTable using AggregatedDataWithUInt8Key = FixedImplicitZeroHashMapWithCalculatedSize\u0026lt;UInt8, AggregateDataPtr\u0026gt;; using AggregatedDataWithUInt16Key = FixedImplicitZeroHashMap\u0026lt;UInt16, AggregateDataPtr\u0026gt;; using AggregatedDataWithUInt32Key = HashMap\u0026lt;UInt32, AggregateDataPtr, HashCRC32\u0026lt;UInt32\u0026gt;\u0026gt;; using AggregatedDataWithUInt64Key = HashMap\u0026lt;UInt64, AggregateDataPtr, HashCRC32\u0026lt;UInt64\u0026gt;\u0026gt;; using AggregatedDataWithShortStringKey = StringHashMap\u0026lt;AggregateDataPtr\u0026gt;; using AggregatedDataWithStringKey = HashMapWithSavedHash\u0026lt;StringRef, AggregateDataPtr\u0026gt;; using AggregatedDataWithKeys128 = HashMap\u0026lt;UInt128, AggregateDataPtr, UInt128HashCRC32\u0026gt;; using AggregatedDataWithKeys256 = HashMap\u0026lt;UInt256, AggregateDataPtr, UInt256HashCRC32\u0026gt;; using AggregatedDataWithUInt32KeyTwoLevel = TwoLevelHashMap\u0026lt;UInt32, AggregateDataPtr, HashCRC32\u0026lt;UInt32\u0026gt;\u0026gt;; using AggregatedDataWithUInt64KeyTwoLevel = TwoLevelHashMap\u0026lt;UInt64, AggregateDataPtr, HashCRC32\u0026lt;UInt64\u0026gt;\u0026gt;; using AggregatedDataWithShortStringKeyTwoLevel = TwoLevelStringHashMap\u0026lt;AggregateDataPtr\u0026gt;; using AggregatedDataWithStringKeyTwoLevel = TwoLevelHashMapWithSavedHash\u0026lt;StringRef, AggregateDataPtr\u0026gt;; using AggregatedDataWithKeys128TwoLevel = TwoLevelHashMap\u0026lt;UInt128, AggregateDataPtr, UInt128HashCRC32\u0026gt;; using AggregatedDataWithKeys256TwoLevel = TwoLevelHashMap\u0026lt;UInt256, AggregateDataPtr, UInt256HashCRC32\u0026gt;; 自适应解压缩 ClickHouse里每列的数据是经过压缩进行存储的。在进行查询时，为了能尽可能减少CPU使用 \u0026amp; 提高查询效率，需要有高效的方式来进行数据解压。\nClickHouse默认使用LZ4算法进行数据的压缩/解压缩。算法的细节这里不进行描述。在进行数据的解压缩时，有一个参数buffSize可以用来控制进行memcpy的buffer大小。经过ClickHouse开发人员的测试，发现对于压缩比较大的数据，使用较大的buffSize可以取得更好的解压速度，反之亦然。那么面临未知的用户数据，如何才能针对性的调节算法的参数，以达到最高的解压效率呢？\nClickHouse 使用了基于 Thompson Sampling 的 Multi-Armed Bandits（多臂老虎机问题, MAB） 算法来挑选出选择最适合当前数据的压缩算法参数。\nMAB问题来源于历史悠久的赌博学，它要解决的问题是：一个赌徒要去玩老虎机，现在有一排外表相同的老虎机，但是每个机器赢钱的概率不一样。他不知道每个机器的概率是多少，那么每次该选择哪个老虎机可以做到最大化收益呢？ 对已知的赢钱概率比较高的老虎机，应该更多的去尝试（exploitation），以获得更多的收益；对未知的或尝试次数较少的老虎机，还要分配一定的尝试机会（exploration），以免错失收益更高的选择，但同时较多的探索也意味着较高的风险（机会成本）。 基于 Thompson Sampling 的 MAB 算法能帮助我们找到获得最大收益的选择，它的流程如下：\n初始化：假设每台老虎机都有一个赢钱的概率p，同时该概率p的分布符合 Beta(wins, loses) 分布。 每个机器都维护两个Beta分布的参数，即wins, loses。初始时认为 wins == loses == 0。使用 Beta 分布的原因是它可以根据 wins 和 loses 的值较为准确的估计出p的分布。 选择老虎机：从每个老虎机的 Beta 分布中 生成一个随机数 r，选择 r 值最大的那台机器进行一次游戏。 更新参数：根据被选中老虎机的游戏结果，若赢钱则该机器的wins增加1，若没赢则loses增加1。更新其 Beta 分布的参数。重复第2步。 仿真：https://learnforeverlearn.com/bandits/ 对应到 ClickHouse 中的实现，它将使用不同参数解压算法的解压速率(picoseconds/byte)作为评估依据。假设数据由若干个block构成，每一个block都使用LZ4进行了压缩。\n初始化：假设每个算法的解压速率符合一个正态分布。初始化时参数（mean, stddev）相同。 选择解压算法：对一个block进行解压时，使用每一个算法的正态分布生成一个随机数 r ，选择 r 值最小的那个算法。 更新参数：记录并计算被选中算法在解压该block过程中的速率。更新到该算法对应的正态分布参数上。对下一个待解压的block数据，重复第2步。 根据19年ClickHouse的一份测试显示，对于使用了4种不同参数的LZ4解压算法来说。使用自适应的LZ4解压算法能提高12%-20%的解压性能。 分布式查询 在集群模式下，由于ClickHouse采用了shared nothing的架构，也提供了对应的分布式查询功能。在ClickHouse中，数据表可以分为 Global 和 Local 两种类型。其中Local表是数据的物理存储，而Global表是对各个节点上多个Local表的抽象，本身并不包含实际数据。\n分布式Select\n当发起对一个节点进行Select查询时，如果查询的是一个Global表，则该节点会将该查询分发到集群中所有其他节点。每个节点对其Local表进行查询后，将结果返回给初始查询节点进行汇聚，并最终返回给客户端。 分布式Join\nClickHouse支持broadcast和local两种方式进行分布式join查询。对于前者，会首先通过分布式select操作获取到join条件中一个完整的表内容，然后将其分发到各个节点，并在各个节点上进行join，最后汇聚。对于后者，join操作完全在各个节点的local表上执行。计算完成后再汇聚到被请求的节点上返回给客户端。 ","permalink":"https://blog.hypertars.com/posts/developer/database/clickhouse/","summary":"基本特性 列式向量 OLAP 数据库 (Column Oriented OLAP) 向量化查询 (Vectorized Query Execution) MPP, Shared Nothing 架构 支持 SQL + extensions 实时查询 (亚秒级) 性能对比 ClickHouse 最显著的特点就是数据分析查询场景下速度快。 单机","title":"ClickHouse"},{"content":"存储方式 宽列存储 / 列簇存储\n实现 DynamoDB - 副本复制模型、无单点失效架构 BigTable - 数据和存储引擎模型\nCategory Dynamo BigTable Arch Decentralized Centralized Data Model Key-Value Column-Oriented API Get, Put Get, Put, Scan, Delete Security No Access control at column-family level Partitioning Consistent Hashing Key range based Replication Across data centers No, Within a single data center in GFS Storage Plug-in SSTables in GFS Read/Write Quorum-like Reads - merge of SSTables and memtable, Writes-tablet log and memtable Concurrency Control Vector clocks with reconciliation during reads Copy-On-Write Membership and failure detection Gossip-based protocol Handshakes initiated by master CAP AP CP 特点 完整的多主数据库复制 高可用, 容错 弹性可扩展 分区的面相键查询 可调节的一致性 AP or CP 无 Schema 写性能高 数据模型 1 2 3 4 5 6 Keyspace: ${KeyspaceName} ColumnFamily: ${ColumnFamilyName} Key: ${Key1, Key2, ...} Columns: {Columns} ${ColumnName} ${Data} Keyspace 每个 Keyspace 包含一个或多个 Table, 一般一个集群只需要一个 KeySpace 属性 副本因子 Replication Factor 是每行数据会复制到多少个节点上。副本因子的选择决定了要为一致性付出多少代价, 所得到的读写的一致性水平取决于副本因子的设定。 副本放置策略 Table 与 ColumnFamily 为相同概念, 类似于关系型数据库里的表。是容纳一个有序的行集合的容器。每一行又是有序的列的集合。向 Cassandra 读写数据时, 可以为一列或多列指定值, 至少包含一个主键值。 1 2 3 4 5 6 7 8 cassandra\u0026gt; getHotelier.Hotel[\u0026#39;NYN_042\u0026#39;] =\u0026gt;(column=zip, value=10019, timestamp=3894166157031651) =\u0026gt;(column=state, value=NY, timestamp=3894166157031651) =\u0026gt;(column=phone, value=2125555555, timestamp=3894166157031651) =\u0026gt;(column=name, value=TheWaldorf=Astoria, timestamp=3894166157031651) =\u0026gt;(column=city, value=NewYork, timestamp=3894166157031651) =\u0026gt;(column=address, value=301ParkAve, timestamp=3894166157031651) Returned 6 results. Column 列是由名称、值和时间戳组成的三元组。相当于表中的一个携带时间戳的单元格。Cassandra 之中不需要预先定义列, 只需要在 keyspace 里定义表就可以写数据了, 所有列的名字都是客户端提供的。使 Cassandra 看起来像四维 Hash: [Keyspace][Table][Key][Column]\n特性\n同一表的行在磁盘上存储在一起 Cassandra 不支持 Join 同一表中, 列是可以根据列名排序的 (一般是字典序, 用于高效地从很宽的行里高效取出一列而无需把每列都读入内存) 除了写入时间外, 还额外存储了 TTL (TTL 是 Column 粒度的) 二级索引\nCassandra允许对列建二级索引, 由于Cassandra将数据划分到多个节点上, 每个节点必须根据存储在相应分区上的数据维护自己的二级索引, 因此二级索引的查询通常涉及多个节点, 导致查询开销显著增加。通常为读性能考虑更倾向于物化视图 (写开销大)。 架构 存储结构 1 2 3 4 5 6 7 Write -\u0026gt; CommitLog -\u0026gt; Memtable -\u0026gt; SSTable -\u0026gt; SSTable -\u0026gt; SSTable -\u0026gt; ... CommitLog - Memtable - SSTable 进行写操作的时候, 数据是直接写入到 commitlog 中的。写操作只有写入到 commitlog 才被认为是成功的, 这样, 即使数据还没有进入内存 memtable 中, 也可以进行数据恢复。 数据写入到 commitlog 中之后, 同时写入内存中名为 memtable 的数据结构之中。当memtable 之中存储的对象数量达到阈值(或者容量达到阈值, 或者达到某时间间隔)之后, memtable 会被刷入磁盘 SSTable 文件中。然后, 创建一个新的 memtable, 接收数据。这个过程是个非阻塞操作, 对于一个表, 可以有多个 memtable, 一个是当前的, 其他的则是等待写入磁盘的。这个过程通常不会很长, 除非节点过载了, 否则刷写的过程应该会很快。 SSTable 的概念是从 Google 的 Bigtable 里借鉴过来的。一旦 memtable 被刷写入磁盘, 成为一个 SSTable, 它就是不可变的了。SSTable 可以合并, 合并是进行了归并排序的“归并”步骤, 将数据并入新的文件, 并删除旧文件。 所有的写操作是顺序进行的, 这是 Cassandra 的写操作性能出众的主要原因。在 Cassandra 之中, 所有的写都是 append 操作, 没有任何读或查找操作。合并操作定期地重新组织数据, 不过合并操作同样也是进行顺序读写。合并操作可以获得更好的读性能。 缓存 Key 缓存: Key -\u0026gt; 行索引的映射 (Key1 - DataPosition1, Key2 - DataPosition2), 存在 JVM 堆上, 默认打开 行缓存: 缓存所有的行, 存在堆外内存, 默认禁用 墓碑 所有的删除操作都转化为更新操作, 在值上放置墓碑, 在合并阶段才真正删除 Bloom Filter 分布式架构 单个 Data Center 使用一致性哈希环的架构 通过 murmur3 算法给 Key 计算 64 位 Hash 值, 去落到不同的节点上。Cassandra 默认支持虚拟节点, 为每个节点分配 256 个令牌。 副本默认策略是放置在环中接下来的 N 个节点中 Gossip 为了做到无中心、容忍网络分裂, Cassandra 使用了一个 gossip 协议来进行环内通信, 这样每个节点都会有其他节点的状态信息。 Gossiper 在定时器的控制下, 每秒钟运行一次。提示移交 (hinted-handoff) 是由 gossip 触发的。当一个节点发现另一个节点重新在线, 而它正好有关于这个节点的提示信息时, 就会触发提示移交。 Gosspier 周期性的运行, 在环里随机选择一个节点, 发起对这个节点的 gossip 回话。每轮 gossip 需要三条消息。不仅交换自身信息, 还交换通过之前的 gossip 通信了解的其他节点信息。所以所有的节点能够很快的了解集群中的其他节点情况。 Gossip 的发起者给它选好的伙伴节点发送一条 GossipDigestSyncMessage 当伙伴节点收到消息时, 回复一条 GossipDigestAckMessage 发起者收到伙伴发回的响应消息后, 再向伙伴发送一条 GossipDigestAck2Message, 以此完成本轮 gossip 相比于一个固定的阈值来标记一个节点为 fail, Cassandra 采用一个自然增长的检测机制来计算每个节点的阈值, 考虑到了网络、负载、历史状况等因素。当进行 gossip 交换时, 每个节点维护了一个其他节点 gossip 信息到达滑动窗口时间。可以通过配置 phi_convict_threshold 属性来调节失败检测的敏感性。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class GossipDigest implements Comparable\u0026lt;GossipDigest\u0026gt; { final InetAddressAndPort endpoint; final int generation; // generation stays the same when server is running and grows every time the node is started final int maxVersion; } public class GossipDigestSyn { final String clusterId; final String partioner; final List\u0026lt;GossipDigest\u0026gt; gDigests; } public class GossipDigestAck { final List\u0026lt;GossipDigest\u0026gt; gDigestList; final Map\u0026lt;InetAddressAndPort, EndpointState\u0026gt; epStateMap; } public class GossipDigestAck2 { final Map\u0026lt;InetAddressAndPort, EndpointState\u0026gt; epStateMap; } hinted handoff 一个写请求到达 Cassandra，但是负责这部分数据的节点却由于网络分裂、硬件故障或其他原因而不可用。为了保证整个环在这种情况下的可用性，Cassandra 实现了一个称为提示移交（hintedhandoff）的机制。 可以把一个提示看做是一个小即时贴，上面记录着写请求的内容。如果写操作所属的节点失败了，Cassandra 接收到该请求的节点会创建一个提示，包含这样一条备忘信息：“我有一个给节点B的写请求信息。这个请求现在挂起了，等到节点B回来的时候请告知我，那时我会把写请求送交给它。”也就是说，写操作的提示信息将会从节点A移交给节点B。 一致性等级 因为Cassandra中的读写操作可以分别指定一致性级别，所以Cassandra的一致性被认为是可调的。\nZERO (deprecated): 在写数据被记录之前就返回；写操作将会在一个后台线程中异步完成，无法确保写操作一定成功\nANY: 集群中任意一台服务器响应（包括HINT）即成功\nONE, TWO, THREE: 集群中任意1/2/3台服务器响应（不包括HINT，即写commitlog成功）即成功\nQUORUM (Most Freq): 集群中响应（不包括HINT）的服务器数量\u0026gt;=ReplicationFactor/2+1即成功。平衡一致性和高可用性的方案。\nLOCAL_QUORUM: 在QUORUM基础上，要求写入成功的节点至少有一台与接受写入操作的服务器属同一DC\nEACH_QUORUM: 在QUORUM基础上，要求写入成功的节点至少有一台与接受写入操作的服务器不属同一DC\nALL: 集群中响应写入成功的服务器数量等于 ReplicationFactor 即成功\n不论是读操作还是写操作, ZERO, ANY, ONE 都被划分为弱一致性, 而 QUORUM 和 ALL 则属于强一致性。在 Cassandra 中, 要达到强一致性, 可以使用如下这个流行的公式: R + W \u0026gt; N =\u0026gt; Strong Consistency。R: Read Replica, W: Write Replica, N: Replication Factor。这时, 所有客户端都可以得到最新的写入结果, 即可以得到强一致性。\n写操作 如果集群跨多个 DC, 本地协调器节点会在其他各个数据中心分别选择一个远程协调器, 每个远程副本直接响应原协调器节点。 一旦有满足一致性级别要求的副本作出响应, 则协调器向客户端确认这个写操作。 读操作 协调器会把请求发给认为最近的 (snich 策略) 一个副本读完整数据本地计算摘要, 从其他副本直接请求摘要, 如果一致且满足一致性要求, 则返回数据。如果摘要不一致, 协调器回完成修复。 事务 Cassandra 支持轻量级事务, 基于 Paxos 共识算法实现 基本 Paxos 算法包含两个阶段: 准备 / 承诺 提议 / 接受。 要修改数据, 会有一个协调器节点担任领导者的角色, 向其他副本节点提出一个新值。其他节点同时担任其他修改的领导者。每个副本节点会检查提议, 如果这个提议看到的是最新提议, 它会承诺不接受之前任何提议关联的提议。每个副本节点会返回它接受的最新提议。如果这个提议被大多数副本接受, 领导者就会提交这个提议, 但需要注意的是, 必须先提交这个提议之前的所有在处理的提议。 Cassandra 实现扩展了基本 Paxos 算法来支持所需的 写前读 语义, 也称为 检查-设置, 并允许在事务之间重置状态。为此, 它在算法中插入了额外的两个阶段, 现在的工作如下: 准备 / 承诺 读 / 结果 提议 / 接受 提交 / 确认 Cassandra 会为每个分区存储一个 Paxos 状态, 可以保证不同分区的事务不会互相打扰。 总结 适用场景 大规模部署: 分布式架构 写密集、统计和分析型: 有高可用性, 有写吞吐量优化 多数据中心结构: 有针对多 DC 设计和相关配置 Category Cassandra CAP AP or CP 通信 Gossip oltp/olap 偏重oltp API 支持SQL语法(通过二级索引) 路由 Snitch算法 语言 Java 设计参考 BigTable and Dynamo License Apache Protocol CQL, binary (Thrift) 数据分布 水平扩展：改进的一致性哈希（虚拟节点） 存储目标 小文件 一致性 可选，一般选最终一致性，Quorum策略 架构 p2p 高可用性 P2P和去中心化设计，不会出现单点故障 伸缩性 扩容需在Hash Ring上多个节点间调整数据分布 读写性能 数据读写定位非常快 数据冲突处理 向量时钟 临时故障处理 数据回传机制：某节点宕机，hash到该节点的新数据自动路由到下一节点做 hinted handoff，源节点恢复后，推送回源节点。 永久故障恢复 Merkle 哈希树，通过Gossip协议同步Merkle Tree，维护集群节点间的数据一致性 成员通信及错误检测 基于Gossip ","permalink":"https://blog.hypertars.com/posts/developer/database/cassandra/","summary":"存储方式 宽列存储 / 列簇存储 实现 DynamoDB - 副本复制模型、无单点失效架构 BigTable - 数据和存储引擎模型 Category Dynamo BigTable Arch Decentralized Centralized Data Model Key-Value Column-Oriented API Get, Put Get, Put, Scan, Delete Security No Access control at column-family level Partitioning Consistent Hashing Key","title":"Apache Cassandra"},{"content":"分布式缓存一致性 缓存系统属于 CAP 中的 AP，BASE 理论，没法强一致性，只能最终一致性\n缓存策略 Cache Aside 对于读操作，先读缓存，读不到就读db，然后回写缓存 对于写操作，会先更新db，然后删除缓存（使缓存失效）。 为什么是删除缓存而不是更新缓存呢？ Read-Through Read Through: 查询操作中更新缓存 存储自己维护自己的 Cache\nRead-Through 和 Cache Aside 很像，但是有两个不同点：\nCache Aside 在缓存 miss 的时候读 db 回写 cache 是在业务代码（Application）中支持该逻辑的，而 Read-Through 是由其他系统回写 cache 的 Cache Aside 由于回写 cache 是业务代码自身控制，所以自由度很高，支持 db 和缓存的数据模型不一致的情况（甚至是跨表跨数据库）；而 Read-Through 只能支持相同数据模型（其实也未必，但是不能跨表和跨数据库是确定的。而且多行对应一个缓存key也不好处理） Write-Through 更新缓存，然后由 Cache 自己更新数据库 存储自己维护自己的 Cache\n虽然看上去 Write-Through 貌似没啥用，但是配合 Read-Through，可以保证数据的最终一致性，而且不需要在更新 DB 后删除缓存。具体参考 AWS DAX\nWrite Back (Write Behind Caching) 先更新缓存，写入缓存成功后直接返回，经过一些延迟后，将缓存中的数据回写db（批量异步更新数据库）\n非强一致性，可能丢失 Lazy Write 这种方式类似于 Page Cache 算法（会丢）、mysql 的 change buffer（不会丢）等常规的算法。\n这种方式能极高地提升写入性能，适用于写入 QPS 极高的服务，配合 Read-Through 可以让数据有很好的一致性。 可以容忍 DB 故障一段时间。 如果 Cache 故障，可能会丢数据 缓存实践：不引入外部系统，纯业务代码处理 Case1 写 DB 成功后更新缓存（不推荐） 对于读请求，先从缓存中读取，如果读取不到，再从 DB 读取，然后写入缓存。 对于写请求，先更新 DB，成功后，更新缓存\n存在问题\n如果同一个操作时间内，有两个以上的更新操作，存在并发更新导致旧更新缓存覆盖了新更新缓存的情况。（如果操作满足 CRDT，那么即使时序不一致，数据也能保证最终一致性） 如果写 DB 成功，更新缓存失败，会导致数据不一致。 Case2 写 DB 成功后删除缓存 对于写请求，先更新 DB，成功后，删除缓存\n存在问题\n对于写请求，更新 DB 成功，删除缓存失败，会导致数据不一致 一个读操作，没有命中缓存，然后到 DB 取数据，此时来了一个写操作，写完 DB 之后，删除缓存，然后读操作再把老的数据读出来放进缓存（几率非常低，RR 隔离级别） 当写操作很频繁的时候，缓存会一直被删除，导致请求一直打到 DB，有打爆 DB 的风险，而且还有主从延迟的问题。 Facebook 有关于该方式的详细论文介绍，里面详细描述了在生产环境中 facebook 是如何使用该方式保证缓存和 DB 的一致性的， Scaling Memcache at Facebook\nCase3 删除缓存后再更新 DB （不推荐） 对于 case2，有同学可能会想到，那我先删除缓存，再修改 DB可以吗？下面我们讨论一下这种case。\n对于写请求，先删除缓存，再更新 DB 存在问题\n如果在删除缓存后，更新 DB 前，来了一个新的读请求，读到了还没更新的 DB 数据，更新到了缓存，缓存和 DB 会不一致 当写操作很频繁的时候，缓存会一直被删除，导致请求一直打到 DB，有打爆 DB 的风险 小结 没有引入任何额外的组件，系统复杂度低；直接操作存储，耗时点，更新快 由于 Cache Aside 无法保证操作同时切成功作用在 DB 和缓存中（即缓存和 DB 的整体事务问题），所以没办法百分百保证数据的一致性。对于这点，我们可以考虑通过 2PC、Paxos 等共识算法，或者另辟蹊径，使用补偿的方式，例如消费 binlog，通过 MQ 进行补偿重试来解决。 有的同学可能会想到：开一个事务，执行写 DB 和更新/删除缓存的操作，如果写缓存失败，就回滚事务。但是 mysql 的连接很宝贵，并发安全写缓存的操作可能会耗尽 mysql 连接。 在并发场景下，没办法保证更新操作的有序性。关于这点，我们可以利用系统本身的有序性来解决，例如利用 binlog 来保证有序性，更新或删除缓存。 缓存实践：引入外部系统结合解决问题 Case1 消费 binlog 删除缓存 写数据\n读数据\n优势\n写操作不再需要耦合缓存操作，与业务代码解耦 解决了删缓存失败导致数据不一致的问题 能保证数据的最终一致性 存在问题\n耗时长，缓存和 DB 存在一定的延迟 因为消费 binlog 到删除缓存这个步骤平均延迟大概 1-3 s，所以会有短时间存在缓存和 DB 不一致的问题。 当更新很频繁的时候，缓存会一直被删除，导致请求一直打到db，有打爆db的风险 Case2 双删 根据Case1 的问题，我们在业务代码更新 DB 成功后也删除一次缓存，来保证实时性。使用 binlog 的删除来保证数据的最终一致性。\n适用场景 该方式比较适合没有热点数据，写请求qps 不高或者大部分都是读几乎没有写的服务\nCase3 消费 binlog 更新缓存 优势\n解耦了业务代码和缓存操作。 因为 binlog 是有序的，所以数据的最终一致性得到了保证 存在问题\nbinlog 延迟比较大，一般 200ms 缓存才能更新 对于一些更新了的数据，不一定会在最近读到，饿汉模式可能会耗费更多的缓存资源 (饿汉模式：缓存本身是解决热点数据问题，所以并不是所有数据都要放入缓存中) 对于 DB 和缓存映射规则复杂（例如多对一）的场景不适用 Case4 双更新 由于通过消费 binlog 更新缓存延迟比较大，我们参考 Case2 的做法，更新 DB 后再更新缓存，然后通过消费binlog 的方式保证数据的最终一致性。\n优势 解决了Case3 更新后 DB 和 缓存短时间内不一致的问题\n存在问题 相比 Case3 ，同时也带来了双写 DB 和缓存时并发写导致短时间的缓存脏数据问题\nCase5 Write Back 优势\n写性能发挥到了极致，全都走高速缓存 不会存在脏数据的问题（因为读写都是同一个数据源，顶多只会存在主从延迟的问题） 存在问题\n数据有丢的可能（crash-safe 完全依赖于缓存本身） 目前很多 NoSQL 数据库对事务支持得不太好，对于需要保证事务的业务需要选择对事务支持比较完善的缓存（下一代分布式事务KV ByteKV详细设计 ） Cache 回写 DB 的过程需要额外设计。例如 cache 容量不够了，需要淘汰数据时，需要先落到 DB；哪些数据适合先回写 DB；什么时候回写 DB 等等。 Case6 Read/Write Through 优势 对业务很友好。业务不需要在业务代码中处理关于缓存和db的关系，通过sdk 直接操作即可。\n存在问题 只能保证最终一致性，对于数据敏感的业务不适用。（取决于Read/Write Through 实现）\n综合选型 缓存策略 优势 存在问题 适用场景 实践 写 DB 成功后删除缓存 1. db和缓存一致率比较高\n2. 没引入外部系统，复杂度低 1. 删缓存失败会导致数据不一\n2. 对于更新很频繁的业务，删缓存的方式可能会导致缓存穿透 1. 读多写少\n2. 可以接受db和缓存有（过期时间内）不一致 Scaling Memcache in Facebook 消费binlog删除缓存 1. 写操作不再需要耦合缓存操作，与业务代码解耦\n2. 解决了写缓存失败导致数据不一致的问题\n3. 能保证数据的最终一致性 1. 耗时长，缓存和 DB 存在一定的延迟\n2. 对于更新很频繁的业务，删缓存的方式可能会导致缓存穿透 1. 读多写少\n2. 可以接受db和缓存有短暂时间的不一致，不存在写后马上读的场景，但是需要保证最终一致性。 双删 消费binlog删除缓存 的全部优点，但是解决了延迟问题 1. 对于更新很频繁的业务，删缓存的方式可能会导致缓存穿透\n2. 在主从延迟的情况，读请求可能还是会读到脏数据 1. 读多写少\n2. 需要保证数据的最终一致性 消费binlog更新缓存 1. 解耦了业务代码和缓存操作。\n2. 因为binlog 是有序的，所以数据的最终一致性得到了保证\n3. 不存在删缓存导致穿透的问题 1. binlog 延迟比较大，一般1s左右 缓存才能更新\n2. 对于一些更新了的数据，不一定会在最近读到，饿汉模式可能会耗费更多的缓存资源\n3. 对于db 和 缓存映射规则复杂（例如多对一）的场景不适用 1. 可以接受db和缓存有短暂时间的不一致，但是需要保证最终一致性\n2. 缓存资源充足\n3. db和缓存映射规则简单\n4. 要求缓存命中率高\n5. 修改cache 的成本不高 双更新 消费binlog更新缓存 的全部优点，但是解决了更新后 DB 和缓存短时间内不一致的问题 同时也带来了双写 DB 和缓存时并发写导致短时间的缓存脏数据问题 1. 可以接受缓存数据有小概率短时间不正确，但是需要保证最终一致性\n2. 缓存资源充足\n3. DB 和缓存映射规则简单\n4. 要求缓存命中率高\n5. 修改cache 的成本不高 Write Back 1. 写性能发挥到了极致，全都走高速缓存\n2. 不会存在脏数据的问题（因为读写都是同一个数据源，顶多只会存在主从延迟的问题） 1. 数据有丢的可能（crash-safe 完全依赖于缓存本身）\n2. 目前很多NoSQL数据库对事务支持得不太好，对于需要保证事务的业务需要选择对事务支持比较完善的缓存\n3. Cache 回写db的过程需要额外设计。例如cache 容量不够 1. 写 QPS 非常高，DB 没办法抗住。（或者要求极高的写性能）\n2. 缓存支持 crash-safe ，故障之后不会丢数据或者业务允许丢数据\n3. 对事务要求不高\n4. 有成熟的cache 回写db 策略。 Read/Write Through 对业务很友好。业务不需要在业务代码中处理关于缓存和 DB 的关系，通过 SDK 直接操作即可。 只能保证最终一致性，对于数据敏感的业务不适用。（取决于Read/Write Through 实现） 1. 读多写少\n2. 不要求强一致读\n3. 业务发展迅速，需要快速迭代开发 AWS DAX Facebook TAO ","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/cache/","summary":"分布式缓存一致性 缓存系统属于 CAP 中的 AP，BASE 理论，没法强一致性，只能最终一致性 缓存策略 Cache Aside 对于读操作，先读缓存，读不到就读db，然后回写","title":"分布式缓存一致性问题"},{"content":"限流是什么 高并发系统在请求过多的时候主动拒绝服务。\n限流：主动对超过一定的请求流量进行拒绝/丢弃\n降级：对所有流量进行拒绝\n过载保护：检测到本身服务（cpu、错误率）到达一定程度，判断当前流量过大，被动保护服务\n熔断：为了保护服务器自发减少或中断请求发放行为（熔断 egress，过载保护 ingress）\nCollaborative Admission Control：统筹过载保护和熔断\n知识树 限流 对象 基于请求限流（QPS） 基于资源限流（库存、金额） 位置 接入层限流（nginx、service mesh） 应用层限流 存储层限流（MySQL、MongoDB） 策略 基于特征（IP、ID） 基于接口限流 粒度 单机限流 集群限流 算法 队列（阻塞队列、有限队列、优先级队列） 计数（固定窗口、滑动窗口） 漏桶 令牌桶（单速双桶、双速双桶、三色双漏桶） 常见限流方式 计数器限流 (Count-based Rate Limiter) 分段计数，固定时间窗口 基本实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 type CountLimiter struct { counter int64 limit int64 intervalNano int64 unixNano int64 } func NewCountLimiter(interval time.Duration, limit int64) *CountLimiter { return \u0026amp;CountLimiter{ counter: 0, limit: limit, intervalNano: int64(interval), unixNano: time.Now().UnixNano(), } } func (c *CountLimiter) Allow() bool { now := time.Now().UnixNano() if now-c.unixNano \u0026gt; c.intervalNano { atomic.StoreInt64(\u0026amp;c.counter, 0) atomic.StoreInt64(\u0026amp;c.unixNano, now) return true } atomic.AddInt64(\u0026amp;c.counter, 1) return c.counter \u0026lt;= c.limit } 问题 瞬时流量拥塞\n突发流量导致毛刺现象，限流不准确\n滑动窗口计数器 (Sliding Window Rate Limiter) 通过更细粒度的滑动窗口计数器解决瞬时流量问题 基本实现 设置成更小的窗口，更细粒度限制流量，使限流变得平滑 如图，每 60 秒请求 100 次，一个大窗口分成 6 个小窗口，每个小窗口可容纳 10 次请求。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 var once sync.Once type slidingWindowLimiter struct { curRequests int32 // 当前请求值 durationRequests chan int32 // 请求队列 accuracy time.Duration // 时间窗口最小单元 snippet time.Duration // 时间窗口时间跨度 curRequestsSum int32 // 当前请求数之和 allowRequests int32 // 最大允许数量 } func NewSlidingWindowLimiter(accuracy, snippet time.Duration, allowRequests int32) *slidingWindowLimiter { return \u0026amp;slidingWindowLimiter{ durationRequests: make(chan int32, snippet/accuracy), accuracy: accuracy, snippet: snippet, allowRequests: allowRequests, } } func (s *slidingWindowLimiter) Take() error { once.Do(func() { // 往前划动一个最小时间窗口 go sliding(s) go calculate(s) }) curRequest := atomic.LoadInt32(\u0026amp;s.curRequestsSum) if curRequest \u0026gt;= s.allowRequests { return ratelimit_kit.ErrExceededLimit } if !atomic.CompareAndSwapInt32(\u0026amp;s.curRequestsSum, curRequest, curRequest+1) { //cas return ratelimit_kit.ErrExceededLimit } atomic.AddInt32(\u0026amp;s.curRequests, 1) return nil } func sliding(s *slidingWindowLimiter) { for { select { case \u0026lt;-time.After(s.accuracy): s.durationRequests \u0026lt;- atomic.SwapInt32(\u0026amp;s.curRequests, 0) } } } func calculate(s *slidingWindowLimiter) { for { \u0026lt;-time.After(s.accuracy) if len(s.durationRequests) == cap(s.durationRequests) { // channel满了 break } } for { \u0026lt;-time.After(s.accuracy) t := \u0026lt;-s.durationRequests if t != 0 { atomic.AddInt32(\u0026amp;s.curRequestsSum, -t) } } } 滑动窗口计数器限流完整实现 1\n滑动窗口计数器限流完整实现 2\n问题 时间区间的精度越高，算法所需的空间容量就越大。\n实现稍微复杂但是依然不能解决计数器边界问题\n令牌桶 (Token Bucket Rate Limiter) 限制输入速率\n令牌桶算法是网络流量整形 Traffic Shaping 和速率限制 Rate Limiting 中最常使用的一种算法\n令牌桶基本处理流程\n产生令牌：周期性地以一定速率（如 100ms）往令牌桶中增加令牌；如果令牌满了，丢弃多余令牌 改进算法实时添加令牌数 消耗令牌：请求来时，从桶中取令牌；如果取到所需数量令牌，则通过；如果取不到，则限流 是否通过：桶中的令牌 \u0026gt;= 所需令牌，否则：直接丢弃 / 进队列等待 / 可以通过但需要特殊标记 基本实现 实际实现采用每次取令牌的时候统计与上次请求的 tick，每次实时更新（而非周期性往桶中增加令牌） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // 每fillInterval时间间隔填充1个token func NewBucket(fillInterval time.Duration, capacity int64) *Bucket { return NewBucketWithClock(fillInterval, capacity, nil) } return \u0026amp;Bucket{ clock: clock, // for mock startTime: clock.Now(), // 启动时间 latestTick: 0, //最后的tick fillInterval: fillInterval, // 每隔多久 capacity: capacity, // 最大的容量 quantum: quantum, // 放入quantum个token availableTokens: capacity, // 当前可用token（初始化为容量 } // take token func (tb *Bucket) take(now time.Time, count int64, maxWait time.Duration) (time.Duration, bool) { if count \u0026lt;= 0 { return 0, true } tick := tb.currentTick(now) tb.adjustavailableTokens(tick) avail := tb.availableTokens - count if avail \u0026gt;= 0 { tb.availableTokens = avail return 0, true } // Round up the missing tokens to the nearest multiple // of quantum - the tokens won\u0026#39;t be available until // that tick. // endTick holds the tick when all the requested tokens will // become available. endTick := tick + (-avail+tb.quantum-1)/tb.quantum endTime := tb.startTime.Add(time.Duration(endTick) * tb.fillInterval) waitTime := endTime.Sub(now) if waitTime \u0026gt; maxWait { return 0, false } tb.availableTokens = avail return waitTime, true } // 计算从令牌桶开始经过了多少个tick （每隔tick会填充quantum的token func (tb *Bucket) currentTick(now time.Time) int64 { return int64(now.Sub(tb.startTime) / tb.fillInterval) } // 计算从上一次tick到现在经过了多少个tick，tick*quantum+available等于目前可以使用的token数量 func (tb *Bucket) adjustavailableTokens(tick int64) { lastTick := tb.latestTick tb.latestTick = tick if tb.availableTokens \u0026gt;= tb.capacity { return } tb.availableTokens += (tick - lastTick) * tb.quantum if tb.availableTokens \u0026gt; tb.capacity { tb.availableTokens = tb.capacity } return } 每次都会更新当前可用的数量（读触发），再减去需求量 令牌桶完整实现 1\n令牌桶完整实现 2\n问题 突刺问题\n在服务器资源空闲的状态下会造成极大的浪费\n漏斗桶 (Leaky Bucket Rate Limiter) 限制输出速率\n请求类似水流，先进入漏桶中，漏桶以一定的速率出水（接口响应速率），当水流速率过大会直接溢出（访问频率超过接口响应速率），然后拒绝请求；若入小于出，则漏桶不起任何作用。\n漏桶以固定速率漏出请求或数据包，平滑突发流量。\n基本实现 每次请求花费 x 秒 (sleep)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 type state struct { last time.Time sleepFor time.Duration } type atomicLimiter struct { state unsafe.Pointer //lint:ignore U1000 Padding is unused but it is crucial to maintain performance // of this rate limiter in case of collocation with other frequently accessed memory. padding [56]byte // cache line size - state pointer size = 64 - 8; created to avoid false sharing. perRequest time.Duration maxSlack time.Duration clock Clock } // 初始化100qps的限流器 rl := ratelimit.New(100) // 计算每个请求需要花多少秒 perRequest := config.per / time.Duration(rate) l := \u0026amp;atomicLimiter{ perRequest: perRequest, // 每个请求要多少秒 maxSlack: -1 * time.Duration(config.slack) * perRequest, clock: config.clock, } // Take blocks to ensure that the time spent between multiple // Take calls is on average time.Second/rate. func (t *atomicLimiter) Take() time.Time { var ( newState state taken bool interval time.Duration ) for !taken { now := t.clock.Now() // 加载上次请求的state previousStatePointer := atomic.LoadPointer(\u0026amp;t.state) oldState := (*state)(previousStatePointer) // 记录当前请求的state newState = state{ last: now, sleepFor: oldState.sleepFor, } // If this is our first request, then we allow it. if oldState.last.IsZero() { taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) continue } // sleepFor calculates how much time we should sleep based on // the perRequest budget and how long the last request took. // Since the request may take longer than the budget, this number // can get negative, and is summed across requests. // 计算这次还要sleep多久 newState.sleepFor += t.perRequest - now.Sub(oldState.last) // We shouldn\u0026#39;t allow sleepFor to get too negative, since it would mean that // a service that slowed down a lot for a short period of time would get // a much higher RPS following that. if newState.sleepFor \u0026lt; t.maxSlack { newState.sleepFor = t.maxSlack } if newState.sleepFor \u0026gt; 0 { newState.last = newState.last.Add(newState.sleepFor) interval, newState.sleepFor = newState.sleepFor, 0 } taken = atomic.CompareAndSwapPointer(\u0026amp;t.state, previousStatePointer, unsafe.Pointer(\u0026amp;newState)) } t.clock.Sleep(interval) return newState.last } 1. perRequest = 每两秒一个请求 2. oldState.last = 上次请求的时间点 3. now.Sub(oldState.last) = 自从上次请求后过了多长时间 4. t.perRequest - now.Sub(oldState.last) = 我想要一个请求，现在过了这么长时间，还差多长时间可以下一次请求 5. newState.sleepFor \u0026gt; 0 说明我还要sleep(newState.sleepFor) 这么长时间，才能进行下一次请求 6. t.clock.Sleep(interval) 执行sleep 漏斗桶完整实现\n问题 突发效率\n当短时间内有大量突发请求时，即便此时服务器没有任何负载，每个请求也得在队列中等待一段时间才能被响应，弹性不够好。\n漏桶算法强制一个常量的输出速率而不管输入流量的突发性，对于存在突发特性的流量来说缺乏效率；与此同时，令牌桶算法能限制数据的平均传输速率之外，还允许某种程度的流量突发，允许最多桶容量大小的突发，但从长期运行结果来看，流量限制为常量。\n自适应限流 （Adaptive Rate Limiter） 根据系统能够承载的最大吞吐量来进行限流，需要一个数据来触发阈值，如机器负载、CPU 使用率、总体平均响应时间、入口 QPS、并发线程数等 自适应限流算法\n自适应限流完整实现\nPID 算法优化 (PID Optimization) 防止小流量场景的误限问题\n区别于传统线性调节，使用微分和积分控制，从不同角度多层次调节输入，使得调节更快的收敛\n参数 解释 用途 KP 目标值减去当前值的系数 从宏观上控制拒绝比例上调还是下降 KI 历史误差的总和（积分）的系数 也称为稳态误差系数，加上历史误差，防止系统在阈值附近不断震荡，维持系统稳定 KD 误差在当前的时刻的导数（微分）的系数 为了能让系统对于突增情况更快做出反应 分布式限流的实现 Redis setnx Redis + Lua Redis + list / zset Redis incr 依赖 redis 的分布式限流使用计数器限流，incr 实现简单，对 redis 的操作较轻，不需要分布式锁，但是会出现流量陡增导致限流边界超过阈值的问题 Go Redis 分布式限流库\n低 QPS 高精度 (~10k) 借助 Redis 中心化存储（redis 桶）；每个时间段一个 redis key（如限制每分钟请求 100 次，则 redis key 为 [prefix]_[minute_timestamp]；每次业务处理前使用 redis incr 获取到的次数和 limit 对照（类似计数器限流）\n单 key 10k QPS\n高 QPS 低精度 (100k+) 核心是批量请求 + 本地缓存 + 自旋锁：\n使用不需要多机房同步的独立 redis 集群作为限流的中心节点，分机房限流，具备横向扩展 sharding 能力 使用本地 token 池存放 step 步长预取，使用 incr by step 方式访问 redis（相比于 decr，incr 不需要 refresh） incrby + expire 计数并清理，无需额外清理 key 步长预取为本地 cache 的 counter（本地桶），每次取 redis 多个 counter，缓解对 redis 请求暴涨带来的存储压力（热 key 问题使得高 QPS 下不得不退化成单实例限流） 热 key 问题：redis 分片，key 前缀增加分片值，对每个分片单独进行限流计算 并发优化：允许本地 token 超发，后续一次性向 redis 申报 预发 token，屏蔽无限流风险的 redis 申报 Step 步长\n引入step 步长概念，限流接口的令牌数量依然在 redis 中存放，但是取令牌数量时不像精准限流器那样一次取一个，而是以步长为单位去取，每次获取单位步长的令牌到本地缓存，新的请求进入需要先去本地的令牌桶中获取令牌，如果本地令牌桶中消耗完之后需要到 redis 桶中再次获取直至 redis 桶中的令牌被消耗完毕。 Step = Min(QPS / 10k + 1, 10k) 单 redis 实例能够支撑最大 100k 简单命令 (incr) 100k QPS 时 step 不会太大而降低限流精度 100m QPS 时，单 key 访问 redis 的频率能够限制在 100k 以内 10b QPS 暂无法支持 高 QPS 高精度 打散步长等手段降低 Redis 调用量，避免热 key 问题 大规模高 QPS 低精度: 集群限流 / 单实例限流 依赖 Service Mesh\n集群限流：使用令牌桶算法，每隔 1 ms 填充，保证时间窗口内发放的总 quota 是限流阈值，最终落在单个实例上做限流\n单实例限流：对每个实例做本地限流配置（令牌桶或滑动窗口）\n敏感耗时限流 方式一：使用单实例限流\n方式二：纯异步分布式限流，存在一定程度漏限率\n","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/limiter/","summary":"限流是什么 高并发系统在请求过多的时候主动拒绝服务。 限流：主动对超过一定的请求流量进行拒绝/丢弃 降级：对所有流量进行拒绝 过载保护：检测到本身服","title":"分布式限流"},{"content":"1. Introduction 为了便于理解，Raft 共识算法做了两件事\n分成了三个子问题，便于理解上手 领导者选举 leader election 日志复制 log replication 安全性 safety 状态简化：对算法做出一些限制，减少状态数量和可能产生的变动 论文：\nhttps://raft.github.io/raft.pdf https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md https://web.stanford.edu/~ouster/cgi-bin/papers/OngaroPhD.pdf 实现\nGolang: https://github.com/hashicorp/raft ETCD: https://github.com/etcd-io/etcd TiKV: https://github.com/tikv/tikv TiDB: https://github.com/pingcap/tidb RocksDB: https://github.com/facebook/rocksdb GoRaft: https://github.com/goraft/raft Animation http://www.kailing.pub/raft/index.html http://thesecretlivesofdata.com/raft/ 共识算法三个主要特性 保证在任何非拜占庭情况下的正确性。可以解决网络延迟、网络分区、丢包、重复发送、乱序问题，无法解决拜占庭问题（存储不可靠、消息错误、分区、冗余、丢失、乱序）。 保证在大多数机器正常的情况下集群的高可用性，而少部分机器缓慢不影响整个集群的性能。 不依赖外部时间来保证日志的一致性。共识算法不受硬件影响，不因外部因素造成错误。但也造成了一些限制，让共识算法受网络影响较大，在异地容灾的情况下，共识算法的支持性比较差。 Raft 共识算法的区别特征 Strong Leader：在 raft 中，日志只能从 leader 流向其他服务器，这简化了复制日志的管理，使得 raft 更好理解。 Leader election：raft 使用随即计时器进行 leader 选举。这只需在任何共识算法都需要的心跳上增加少量机制，同时能够简单快速地解决冲突。 Membership changes：raft 使用一种共同一致 joint consensus 方法来处理集群成员变更的问题，变更时，两种不同的配置大多数机器会重叠，这允许整个集群在配置变更期间可以持续正常运行。 长声明周期的强 leader，是 raft 实现起来简单，区别于其他共识算法最重要的特点，同时也存在性能隐患。raft 选举出来的 leader 必须具有日志完整性。为了保证时时刻刻都能有具备完整日志的节点可以成为 leader，raft 必须使用顺序日志复制的方法来避免日志空洞。这一套是 raft 的三个子问题领导者选举、日志复制、安全性的三个闭环逻辑。为了支持强 leader，raft 单独分解出了领导者选举这个子问题。并用安全性子问题来保证选举出的 leader 具有完整日志，以及处理 leader 宕机的情况。强 leader 使得共识算法中最重要的日志复制模块实现起来很简单，同时也极大降低了 raft 实现和理解的难度。 2. Paper 2.1 复制状态机 Replicated State Machine 相同的初始状态 + 相同的输入 = 相同的结束状态 多个节点上，从相同的初始状态开始，执行相同的一串命令，产生相同的最终状态。 在 Raft 中，leader 将客户端请求 (command) 封装到一个个 log entry 中，将这些 log entries 复制到所有 follower 节点，然后大家按相同顺序应用 log entries 中的 command，根据复制状态机的理论，大家的结束状态肯定是一致的。 实现共识算法就是为了实现复制状态机。一个分布式场景下的各节点间，就是通过共识算法来保证命令序列的一致，从而始终保持他们的状态一致，从而实现高可用。 同时，复制状态机的功能可以更加强大，比如两个副本一个采用行存储（更适合 OLTP），一个采用列存储（更适合 OLAP），只要初始数据相同，并持续发给相同的命令，那么同一时刻从两个副本中读取到的结果也是一样的。这就是 HTAP（Hybrid Transaction and Analytical Process 混合事务和分析处理） 的实现方法（如 TiDB）。 共识算法的本质是实现复制状态机（目的即为容错，但是实现之后可以有更多用处）。 构建分布式存储系统，是为了获取更大的存储容量 Scalability 为了获取更大的存储容量，把数据进行分片 Sharding 更多的机器带来了更高的出错频率 Fault 为了容错 Fault Tolerance，对每个分片建立副本 Replication 为了维持副本间的一致，引入共识算法 Consensus 而共识算法会需要额外的资源与性能 Low Performance，这里又会反过来影响系统的容量和分片数设计 应用 数据量小：集群成员信息、配置文件、分布式锁、小容量分布式任务队列 无 leader 的共识算法（Basic Paxos）：Chubby、Zookeeper 数据量大：大规模存储系统 有 leader 的共识算法（Multi Paxos、Raft）：GFS、HDFS 数据量大，数据之间还存在关联：数据分片 partition 到多个状态机中，通过两阶段提交 2PC 保证一致性 Spanner、OceanBase、TiDB 等支持分布式事务的分布式数据库 2.2 状态简化 Raft Basics 任何时刻，一个服务器节点都处于 leader、follower、candidate 三个状态之一。 相较于 Paxos，极大简化了算法的实现，因为 Raft 只需要考虑状态的切换，而不用像 Paxos 考虑状态之前的共存和相互影响。 任何一个节点启动时都是 follower 状态 如果察觉到集群中没有 leader 的话，就会转换为 candidate 状态（第一个发现的先发优势大概率会成为 leader） 在 candidate 状态下经历一次或多次选举，如果选举结果是自己成为 leader，就会转换为 leader 状态，并为客户端提供服务；否则切换为 follower 状态 如果 leader 状态任期结束或者自身发生宕机等其他问题，就会转换为 follower 状态进入下一轮循环 Raft 把时间分割为任意长度的任期 (term)，任期用连续的整数标记（通常为 int）。 每一段任期从一次选举开始。在某些情况下，一次选举无法选出 leader（比如两个节点收到了相同的票数），在这种情况下，这一任期会以没有 leader 结束；一个新的任期（包含一次新的选举）会很快重新开始。Raft 保证在任意一个任期内，最多只有一个 leader。 任期的机制可以非常明确地标识集群的状态，并且通过任期的比较，可以确认一台服务器历史的状态，根据一台服务器是否有某个任期的日志确认其该期间是否宕机。 Raft 算法中服务器节点使用 RPC 进行通信，并且 Raft 中只有两种主要的 RPC RequestVote RPC（请求投票）：由 candidate 在选举期间发起 AppendEntries RPC（追加条目）：由 leader 发起，用来复制日志和提供心跳机制 服务器之间通信的时候会交换当前任期号，如果一个服务器上的当前任期号比其他的小，该服务器会将自己的任期号更新为较大的那个值。 如果一个 candidate 或者 leader 发现自己的任期号过期了，他会立即回到 follower 状态 如果一个节点接收到一个包含过期的任期号的请求，他会直接拒绝这个请求。 2.3 领导者选举 Leader Election Raft 内部有一种心跳机制，如果存在 leader，那么会周期性地向所有 follower 发送心跳，来维持自己的地位。如果 follower 一段时间没有收到心跳，他会认为系统中没有可用的 leader，然后开始进行选举。\n开始一个选举过程后，follower 先增加自己的当前任期号，并转换到 candidate 状态，然后投票给自己，并且并行地向集群中的所有其他服务器节点发送投票请求（RequestVote RPC）\n选举最终会有三种结果\n它获得超过半数选票赢得选举：成为 leader 并开始发送心跳 其他节点赢得了选举：收到新 leader 的心跳后，如果新 leader 的任期号不小于（大于等于）自己当前的任期号，那么就从 candidate 回到 follower 状态。 一段时间后没有任何获胜者：每个 candidate 都在一个自己的随机选举超时时间后增加任期号开始新一轮投票。 为什么会没有获胜者？比如有多个 follower 同时称为 candidate，得票过于分散，没有任何一个 candidate 得票超过半数。\n当前选举阶段没有产生任何 leader 并不需要集群中所有节点对此产生共识，而是通过每个 candidate 都在等待一个随机选举超时后，默认进入下一个选举阶段。\n随机选举超时时间？150 - 300ms \u0026lt;img src=\u0026ldquo;http://thesecretlivesofdata.com/raft)\n对于没有成为 candidate 的 follower 节点，对于同一任期，会按照先来先得的原则投出自己的选票。\nRequestVote RPC 中要有 candidate 最后一个日志的信息：安全性子问题会给出进一步说明。\n请求和返回都带有 term 任期号，Raft 需要通过任期号确定自身状态并判断接不接受该 RPC。\nFollower 投票逻辑\nterm 是否比自己大 lastLogIndex、lastLogTerm 安全性检查。 每个 follower 只有一张选票，先来先得。 请求投票 RPC Request (Golang) Arguments by candidates\n1 2 3 4 5 6 type RequestVoteRequest struct { Term int // 自己当前的任期号 CandidateID int // 自己的 ID LastLogIndex int // 自己的最后一个日志号（安全性） LastLogTerm int // 自己最后的一个日志任期（安全性） } 请求投票 RPC Response (Golang) Results by followers\n1 2 3 4 type RequestVoteResponse struct { Term int // 自己当前任期号 VoteGranted bool // 自己会不会投票给这个 candidate } 2.4 日志复制 Log Replication Leader 被选取出来后开始为客户端提供服务。客户端随机向一个节点发送请求（或老 leader），如果这个节点正好是 leader，执行指令即可。若该节点是 follower，其根据心跳告知客户端该找谁。如果该节点正好宕机，客户端会找另一个节点重复上述操作。Raft 保证集群超过半数节点可用即可提供正常服务。\nLeader 接收到客户端的指令后，会把指令作为一个新的条目追加到日志中。\n一条日志中需要有三个信息\n状态机指令 leader 的任期号：检测多个日志副本之间的不一致情况和判定节点状态；每个方块上的数字即任期号，一个任期用一个颜色标记。 日志号（日志索引）：区分日志前后关系，在图最上方，单调递增。leader 宕机会造成日志号相同的日志内容却不同，所以只有日志号和任期号才能唯一确定一个日志。 生成日志后，leader 会并行发送 AppendEntries RPC 给所有 follower，这样 follower 可以按照 leader 的日志顺序接收，复制该条目。当该条目被超过半数 follower 复制后，leader 就可以在本地执行该指令并把结果返回客户端。\n本地执行命令，也就是 leader 应用日志到状态机这一步，称作提交。\n若 leader 在提交之前宕机，虽然日志复制到了超过半数的节点，但没能提交。 Raft 一致性检查：leader 在每一个发往 follower 的追加条目 RPC 中，会放入前一个日志条目的索引位置和任期号，如果 follower 在它的日志中找不到前一个日志，那么它就会拒绝此日志，leader 收到 follower 的拒绝后，会发送前一个日志条目，从而逐渐向前定位到 follower 第一个缺失的日志。\n优化不必要：失败不太可能发生，也不太可能会有很多不一致的日志条目。 可能的优化：follower 包含冲突条目的任期号和自己存储的那个任期第一个 index，leader 可以跳过那个任期内所有冲突的日志条目来减小 nextIndex，这样每个有冲突日志的条目的任期需要一个 AppendEntries RPC 而不是每个条目一次。 leader 或 follower 随时都有崩溃或缓慢的可能性，Raft 必须要在有宕机的情况下继续支持日志复制，并且保证每个副本日志顺序一致，以保证复制状态机的实现。follower 追不上 leader 有三种情况。\nfollower 缓慢：如果有 leader 因为某些原因没有给 leader 响应，那么 leader 会不断重发追加条目请求（AppendEntries RPC），哪怕 leader 已经回复了客户端（超过半数节点回复，已提交）。 follower 宕机：如果有 follower 崩溃后恢复（可能期间已经换了几个 term 甚至几个不同 leader），这时 Raft 追加条目的一致性检查生效，保证 follower 能按顺序恢复崩溃后的缺失日志。 leader 宕机：leader 上可能有未提交的日志，而投票选举阶段不考虑这些日志。这意味着新选出的 leader 可能不具备这些未提交的日志。这里对外是可以接受的，客户端会认为那些未提交的日志是直接失败的，不会影响一致性。但是 leader 宕机后恢复因为这些未提交的日志会和新 leader 的日志产生冲突。老 leader 在恢复后成为 follower，进行一致性检查的过程中会发现自己最后的几个日志和新 leader 的日志不同，一些复制了未提交日志的 follower 也可能遇到这种情况。 如图，最上面为当前 leader，此时 follower 中的 c 和 d 比这个 leader 还多出两个日志，但是这些多出的日志并未提交，所以不构成多数。在这个集群中，leader 可以依靠 a b e f 和自己的选票当选 leader。 此时，raft 通过强制 follower 复制 leader 的日志来解决不一致的问题，因为这部分达成共识的才是真正已提交的。leader 通过一致性检查，找到最后一个和自己一致的 follower 之后，就会把这之后和自己冲突的所有日志全部覆盖掉，因为抛弃未提交的日志是不违反一致性的。所以 c d e f 中和 leader 不一致的日志都会被覆盖掉。 而如果此时当前 leader 宕机，那么 a c d 是有机会成为 leader 的。若 c 和 d 成为 leader，就会将当前自己多出来的日志复制给 follower，再提交。 通过日志复制机制，leader 在当权之后不需要任何特殊的操作来使日志恢复到一致状态。其只需要按规则一直发送 AppendEntries RPC，follower 在回复 AppendEntries RPC 进行一致性检查时就可以自动趋于一致。\nleader 从来不会覆盖或删除自己的日志条目，这样的复制机制可以保证一致性。（Append-Only）\n只要过半的服务器能正常运行，Raft 就能够接受、复制并应用新的日志条目 在正常情况下，新的日志条目可以在一个 RPC 来回中被复制给集群中的过半机器 单个运行慢的 follower 不会影响整体的性能。 追加日志 RPC Request (Golang)\n1 2 3 4 5 6 7 8 type AppendEntriesRequest struct { Term int // 当前自己的任期号 LeaderID int // leader（也就是自己）的ID PrevLogIndex int // 前一个日志的日志号，一致性检查 PrevLogTerm int // 前一个日志的任期号，一致性检查 Entries []LogEntry // 当前日志体 LeaderCommit int // leader 的已提交日志号（安全性） } 只有 leader 确认过半节点成功接收后才会提交，此时 follower 才可以真正提交。如果 LeaderCommit \u0026gt; CommitIndex，那么把 CommitIndex 设为 min(LeaderCommit, Index of Last New Entry)，即这一段的所有日志都是可以提交的。即 follower 会比 leader 晚一个日志的提交。\n追加日志 RPC Response (Golang)\n1 2 3 4 type AppendEntriesResponse struct { Term int // 当前自己的任期号 Success bool // 如果 follower 包括前一个日志成功 } Success 必须 RequestTerm \u0026gt;= 自己的 Term，且通过一致性检查\n2.5 安全性 Safety 领导者选举和日志复制两个子问题实际上已经涵盖了共识算法的全程，但这两点还不能完全保证每一个状态机会按照相同的顺序执行相同的命令。这里日志应用到状态机的顺序是一定不能颠倒的，很多共识算法为了效率允许日志乱序复制到非 leader 的节点，这样会导致日志中出现很多空洞，造成非常多的边界情况需要处理。Raft 为了简化设计，避免了这些边界情况的复杂处理，在日志复制阶段就保证了日志的有序性且无空洞。 日志复制阶段对于顺序的保障是 leader 是正常工作的，如果 leader 出现宕机，末尾日志的状态就有可能不正常。。此时新 leader 是否具备这些不正常日志以及如何处理这些不正常日志十分关键，这也是 Raft 为数不多的需要处理的边界情况。安全性即 Raft 通过定义几个补充规则完善整个算法，可以在各类宕机问题下都不出错。\nLeader 宕机处理：选举限制\n如果一个 follower 落后了 leader 若干条日志（但没有漏一整个任期），那么下次选举中，按照领导者选举里的规则（任期号+1），依旧有可能当选 leader。它当选 leader 后就永远也无法可能补上之前缺失的日志，从而造成状态机之间的不一致。 所以，需要对领导者选举增加一个限制，保证选出来的 leader 一定包含了之前各任期的所有被提交的日志条目。 Raft 通过 RequestVote RPC 中最后两个参数 LastLogIndex 和 LastLogTerm 来实现这个限制。如果投票者自己的日志比 candidate 还新，那么他会拒绝掉这个投票请求。 新即比较两个日志中最后一条日志条目的索引值和任期号来定义谁的日志比较新。 如果两个日志最后条目的任期号不同，则任期号大的日志更新。 如果两个日志最后条目的任期号相同，日志较长（日志号更大的）日志更新。 下图 a 中 S1 是 leader；b 中 S1 崩溃后 S5 通过 S3 S4 选票赢得选举；c 中 S5 崩溃，S1 重启并选举成功，此时日志 2 已经被复制到了大多数机器上，但还没有被提交；d 中 S1 再次崩溃，S5 通过 S2 S3 S4 的选票能够再次选举成功。 为什么 S2 S3 会投票给 S5？因为其日志相同，但是 S5 的任期号更大。 日志 2 被复制到了大多数机器上但还未提交，由问题 2 来解决。 Leader 宕机处理：新 leader 是否提交之前任期内的日志条目\n一旦当前任期内的某个日志条目已经存储到过半的服务器节点上，leader 就知道该日志可以被提交了。此时 leader 应用日志到自己的状态机上并返回给客户端，但是 follower 并没有应用到自己的状态机上，没有提交，所以对整个集群来说提交这个状态并没有构成大多数。 follower 如何知道自己可以提交？follower 的提交触发：下一个 AppendEntries RPC 中的 LeaderCommit 参数，通过该参数 follower 可以知道 leader 提交到了哪个日志，从而自己也可以引用这个日志。所以 follower 的提交在下一个日志或者心跳（心跳也是一种特殊的 AppendEntries RPC，和普通的相比缺少日志体）。 而在 leader 提交给客户端到通知 follower 提交之前（一个心跳时间内），如果 leader 宕机那么会出现返回给客户端成功，但是 follower 不会提交的情况。 单点提交 vs 集群提交？对于这个问题而言，raft 是一种底层的共识算法，和客户端的交互不应该是 raft 应该担心的，要避免这个问题，应用可以设置一个集群提交的概念，只有集群中超过半数的节点都完成提交，才认为集群提交完成，leader 可以通过 follower 返回的 success 与否判定这个是否已完成提交，所以 leader 可以很容易判断一个日志是否符合集群提交的条件（类似分布式事务 2PC）。然而实际上 leader 单点提交后就返回客户端，已经是安全的了，没有等待集群提交的必要。 对于分布式数据库而言，分布式提交阶段的宕机是很难处理的，很多时候 leader 一宕机，与 client 的连接就断了，很容易造成 commit 状态未知，后续 client 很难确认提交的最终状态。Ref：Google Percolator 事务模型。 如果某个 leader 在提交某个日志条目之前崩溃了，以后的 leader 会试图完成该日志条目复制（而非提交）。通过选举规则可以知道，一般情况下新 leader 一定有老 leader 已提交的日志，但这些老日志可能在新 leader 中还没有提交，这时新 leader 会尝试将这个日志复制给其他所有 follower。 如果某个 leader 在提交某个日志条目之前崩溃，以后的 leader 会试图完成该日志条目的复制（而非提交，不能通过心跳提交老日志）。 c 到 d 的情况，哪怕 S1 当选 leader，把日志 2 复制到了大多数节点，最终却被日志 3 覆盖了，也就是没有在集群中提交日志 2。如果 S1 在 c 时提交了日志 2，就会出现不一致，因为日志 2 的任期号是老的 2，假设 c 中 S1 重新当选 leader，在 S1 S2 S3 中都把日志 2 提交了，这时候集群中的大多数节点都提交了，若此时 S1 宕机，集群重新选举，S5 依靠最高的任期号 3，依旧可以拿到 S2 S3 S3 的选票，从而覆盖 日志 2，进入 d 的情况。 Raft 永远不会通过计算副本数目的方式来提交之前任期内的日志条目。只有自己任期内的日志才能通过计算副本数目来提交，因为可以确认自己当前的任期号是最大的。即新 leader 提交是危险的，但是复制是安全的，依旧会把老日志复制到 follower 节点。 在新 leader 在它的任期内产生一个新日志，在这个日志提交时，就可以提交这些老日志（如图中 c 到 e）。必须要是新任期内的日志提交，因为此时新 leader 才能把自己的 LeaderCommit 设置为新任期内日志的日志号。相当于用新 leader 新任期内的日志保护了老任期内的日志，这样老任期内的日志就不会再覆盖了。 Leader 宕机 Animation: Raft Scope \u003c!DOCTYPE HTML\u003e Follower 和 Candidate 宕机处理\nFollower 或 candidate 崩溃了，那么后续发送给他们的 RequestVote 和 AppendEntries RPC 都会失败。 Raft 用无限的重试在处理这种失败。如果崩溃的机器重启了，那么这些 RPC 就会成功地完成。 如果一个服务器在完成了 RPC，但是还没有响应的时候崩溃了，那么它重启之后就会再次收到同样的请求，Raft 的 RPC 都是幂等的。 时间与可用性限制\nRaft 算法整体不依赖客观时间，哪怕因为网络或其他因素，造成后发的 RPC 先到，也不会影响 Raft 的正确性（这点和 Google Spanner 不同） 只要整个系统满足 广播时间 Broadcast Time \u0026laquo; 选举超时时间 Election Timeout \u0026laquo; 平均故障时间 MTBF，Raft 就可以选举出并维持一个稳定的 leader 广播时间和平均故障时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPC 需要接受并将信息落盘，所以广播时间大概是 0.5ms - 20ms，取决于存储技术。因此，选举超时时间可能需要设置在 10ms - 500ms 之间。大多数服务器的平均故障时间间隔都在几个月甚至更长。 Raft 实现常用补丁 no-operation 一个节点当选 leader 后，立刻发送一个自己当前任期的的空日志体的 AppendEntries RPC。这样就可以把之前任期内满足提交条件的日志都提交了。 一旦 no-op 完成复制，就可以把之前任期内符合提交条件的日志保护起来了，从而就可以使他们安全提交。因为没有日志体，这个过程应该是很快的。 2.6 集群成员变更 Cluster Membership Changes 在需要改变集群配置的时候（增减节点、替换宕机机器、改变复制程度），Raft 可以进行配置变更自动化。\n难点：保证转换过程中不会出现同一任期的两个 leader，因为转换期间整个集群可能划分为两个独立的大多数。（脑裂问题）\n下图为三节点（S1 S2 S3）集群扩容到五节点（S1 S2 S3 S4 S5）\nS1 S2 为老配置集群，S3 S4 S5 为新配置集群 老配置为三节点，S1 S2 可以选出一个 leader （2票/3总） 新配置为五节点，S3 S4 S5 可以选出一个 leader （3票/5总） 两阶段配置变更\n集群先切换到一个过渡配置，称为联合一致（joint consensus） 第一阶段，leader 发起 C(old, new)，使整个集群进入联合一致状态。此时，所有 RPC 都要在新旧配置中都达到大多数才算成功。（AppendEntries RPC）避免脑裂的核心问题点。 第二阶段，leader 发起 C(new)，使整个集群进入新配置状态。这是，所有 RPC 只要在新配置下能达到大多数就算成功。 一旦某个服务器将该新配置日志条目增加到自己的日志中，他就会用该配置来做出未来所有的决策（服务器总是使用它日志中的最新配置，无论该配置日志是否已被提交）。\n这意味着 leader 不用等待 C(old, new) 和 C(new) 返回，只要发出去之后，就会直接使用其中的新规则来做出决策。 假设 leader 可以在集群成员变更任何时候宕机，有如下几种可能。\nleader 在 C(old, new) 未提交时宕机：raft 还未进入联合一致状态，这时 leader 宕机，可以仅靠老配置选出新 leader。 leader 在 C(old, new) 已提交但 C(new) 未发起时宕机：raft 集群进入联合一致状态，这时 leader 宕机，选出的新 leader 也要符合联合一致的选票规则。 leader 在 c(new) 已发起时宕机：集群可以仅靠新配置进行选举和日志复制。 缩减集群的情况下，leader 可能自身就是缩减的对象，那么它会在 C(new) 复制完成后自动退位。 增加 S4 S5 后，raft 会先将其设置为只读，等其追上日志进度后，才会开始集群成员变更。\n现任 leader S3 发起 C(old, new)，并复制给了 S4 S5，此时有可能出现脑裂，S3 S4 S5 已经进入了联合一致状态，他们的决策要在新旧两个配置中都达到大多数才算成功。\nleader 在 C(old, new) 未提交时宕机：此时 S1 S2 都是老配置，开始进行选举，并且可以以 （2/3） 产生一个老配置的 leader，但是在联合一致状态下，S3 S4 S5 中的任意节点必须要在老配置 S1 S2 S3 和新配置 S1-S5 下都拿到超过半数的选票才能当选，因为 S1 S2 投票给了他们之中的一个节点，所以在老配置中超过半数的条件是不满足的，导致 S3 S4 S5 中无法再选出一个 leader，这样集群变更就失败了，但是可以避免出现两个 leader 的脑裂情况。这里还有一种可能，重新选出的新 leader 具有 C(old, new)，如下图 S1 S3 S4 S5 都复制了C(old, new)，但还没有提交，从而选出来的新 leader 可以具有C(old, new)，但是按照安全性的限制，这新 leader 无法提交C(old, new)，不过可以让其继续发送 C(new)，继续进行集群成员变更。 leader 在 C(old, new) 已提交但 C(new) 未发起时宕机：假设 S3 没有宕机，正常复制 C(old, new) 满足联合一致条件，如图中 S2 S3 S4 都复制了C(old, new)，这时老配置中 S2 S3 超过了半数，新配置中 S2 S3 S4 也超过了半数，这时 C(old, new) 就可以提交了，若 C(new) 在未发起时发生了宕机，选举限制安全性规则决定了选出的新 leader 一定是具有 C(old, new) 的，也就是符合在两种配置集群中都超过半数的情况，所以不存在出现脑裂问题。此外，集群变更状态过程中，在联合一致的状态下也是可以正常执行命令，对外提供服务的，但是需要在两个配置集群中都达到大多数，才可以提交日志。C(old, new) 提交后，leader 就会发起 C(new)，这时 leader 只要满足新配置中的条件，就可以提交日志。 leader 在 c(new) 已发起时宕机：S3 S4 S5 都复制了 C(new) 日志，C(new) 就可以提交了，不用再在 S1 S2 S3 中达到大多数了，这时若 S3 发生宕机，已复制了 C(new) 的节点，会只按照新配置进行选举，没有复制 C(new) 的节点，会按照新老配置选举。不论是否复制到 C(new) 节点都有可能当上 leader，但没有复制到 C(new) 的节点，选举成功也会发送 C(new)，这里不会有问题。 leader 在 c(new) 已提交后宕机：但是有一种缩减节点的情况如 S1 - S5 缩减为 S1 S2 S3，C(old, new) 仍需要复制到两个集群中的大多数才能提交，但 C(new) 只需要复制到 S1 S2 S3 中的两个就可以提交了。这时如果 S3 宕机，已提交的 C(new) 并不会被覆盖。因为处于联合一致状态的节点，也就是只复制了 C(old, new)，没有复制 C(new) 的节点，必须要在两个集群中都达到大多数选票才能够选举成功。而 S2 S3 不会投票给 S1 S4 S5 中的任意一个。所以 S3 若发生宕机，只有 S2 才可以当选，已提交的 C(new) 并不会被覆盖。 C(old, new) 的复制满足了在新老配置中都超过半数的条件，但 leader 宕机，这时新 leader 无法提交 C(old, new)，但继续发 c(new) 的情况。如图中，leader S3 复制 C(old, new) 到了新老配置的大多数节点，满足联合一致，但 S3 未提交 C(old, new) 就宕机了。这时 S1 当选 leader，根据安全性规则，S1 不可以直接提交 C(old, new)，所以 S1 只能继续复制 c(new)，这时其把 c(new) 复制到了 S1 S4 S5 节点，构成了新配置集群的大多数，但这时其并不能提交，因为没有 S3 的反馈， C(old, new) 的提交规则并没有满足，这样提交的 c(new) 会把 C(old, new) 一并提交，是不安全的。论文中没有给出这种情况的解决方法，但是某些实现中，可以强制让 c(new) 按照联合一致的规则提交。如果当前 leader 在一段时间后还满足不了这个提交条件，那么其就会自动退位。\n集群成员变更补充规则\n新增节点时，需要等新增的节点完成日志同步再开始集群成员变更。防止集群在新增节点还未同步日志时就进入联合一致状态或新配置状态，影响正常命令日志提交。 缩减节点时，leader 本身可能就是要缩减的节点，这时它会在完成 c(new) 的提交后自动退位。在发起 c(new) 后，要退出集群的 leader 就会处在操纵一个不包含它本身的 raft 集群的状态下，这时它可以发送 c(new) 日志，但是日志计数时不计自身。 为了避免下线的节点超时选举而影响集群运行，服务器会在它确信集群中有 leader 时拒绝 RequestVote RPC。因为 c(new) 的新 leader 不会再发送心跳给要退出的节点，如果这些节点没有及时下线，他们会超时增加任期号后发送 RequestVote RPC。虽然他们不可能当选 leader，但会导致 raft 集群进入投票选举阶段，影响集群的正常运行。为了解决这个问题，Raft 在 RequestVote RPC 上补充了一条规则：一个节点如果在最小超时时间之内收到了 RequestVote RPC，那么它会拒绝此 RPC。这样，只要 follower 连续收到 leader 的心跳，那么退出集群节点的 RequestVote RPC 就不会影响到 raft 集群的正常运行了。 这种集群成员变更方法被称为 joint consensus 方法，或多节点变更方法。\n由于上述方法边界情况较多较为复杂，实际实现大多基于另一种单节点变更方法，可以极大简化变更难度。即：一次只增减一个节点，新旧配置集群的大多数是一定会有重合的。这样，就可以不经过联合一致，直接从老配置切换到新配置。如果要变更多个节点，只需要多次执行单节点变更即可。\ncons：联合一致支持机器替换，abc -\u0026gt; bcd 仅需一次变更，单节点方法需要 abc -\u0026gt; abcd -\u0026gt; bcd cons：选择集群的高可用节点数时一般选择奇数来达到多数派的最高性价比，单节点变更过程必然会出现偶数个节点的情况。 TiDB 的解决方法：优化偶数节点集群的大多数概念。因为只需要让新老配置集群有交集就可以了，所以老配置的任意两个节点，如 ab ac bc 也可以作为变更过程中四节点的大多数，来让 c(new) 提交。因为 ab ac bc 是新老配置的最小交集，只要他们都复制了 c(new)，就可以保证选出的新 leader 是应用了最新配置的，不会发生脑裂问题。 TiDB 在 Raft 成员变更上踩的坑 后分布式时代：多数派读写的少数派实现 cons：连续两次变更，第一步变更如果出现了切主，那么紧跟着的下一次变更可能出现错误。 解决办法：新 leader 必须提交一条自己任期内的 no-op 日志，才能开始单节点集群成员变更。可以通过 no-op 把未提交的 c(new) 覆盖掉。 Raft 成员变更的工程实践 总结 Raft 五条公理\n特性 解释 选举安全特性 对于一个给定的任期号，最多只会有一个领导人被选举出来 领导人只附加原则 领导人绝对不会删除或者覆盖自己的日志，只会增加 日志匹配原则 如果两个日志在相同的索引位置的日志条目的任期号相同，那么久认为这个日志从头到这个索引位置之间全部相同 领导人完全特性 如果某个日志条目在某个任期号中已经被提交，那么这个条目必然出现在更大任期号的所有领导人中 状态机安全特性 如果一个领导人已经将给定的索引值位置的日志条目应用到状态机中，那么其他任何的服务器在这个索引位置不会应用一个不同的日志 2.7 日志压缩 Log Compaction 需要一个机制清理 raft 上的 log，否则随着事件积累会打爆状态机的内存\n如何判断日志可清理？使用快照技术，类似关系型数据库。每个节点达到一定条件后，可以把当前日志中的命令都写入自己的快照，然后就可以把已经并入快照的日志都删除了。\n快照中一个 key 只会留有最新的一份 value，占用空间比内存小得多。\n如果一个 follower 落后 leader 很多，如果老的日志被清理了，leader 怎么同步给 follower 呢？ raft 的策略是直接向 follower 发送自己的快照。\n如下图，把日志 5 及之前的日志都并入快照。这部分日志将被直接清理。 因为大型分布式系统的状态机一般都很大，使用快照同步会比单一状态同步慢，因此何时进行快照、内存占用率等等也成为一个重要调参方向。\n2.8 读操作处理 Read Only Operation 直观上讲，raft 的读只要直接读取 leader 上的结果就行了 直接从 leader 的状态机取值，实际上并不是线性一致性读（一般也称作强一致性读） 线性一致性读：读到的结果是读请求发起时已经完成提交的结果（快照） 在 leader 和其他节点发生了网络分区的情况下，其他节点可能已经重新选出了一个 leader，如果老 leader 在没有访问其他节点的情况下直接拿自身的值返回给客户端，这个读取的结果就有可能不是最新的。 所以，要追求强一致性读的话，就需要让这个读的过程或结果，也在大多数节点上达到共识。 稳妥的方法：把读也作为一个 log，由 leader 发到所有的节点上寻求共识，这个读的 log 提交后，得到的结果一定符合线性一致性。 优化后的方法要符合以下规则： 线性一致性读一定要发往 leader 如果一个 leader 在它的任期内还没有提交一个日志，那么它要在提交了一个日志后才能反馈 client 的读请求（可以通过 no-op 补丁来优化）。因为只有在自己任期内提交了一个日志，leader 才能确认之前任期的哪些日志已经被提交，才不会出现已提交的数据读取不到的情况。 在进行读操作前，leader 要向所有节点发送心跳，并得到大多数节点的反馈，确保自己仍是 leader leader 把自己已提交的日志号设为 readIndex，只要 leader 应用到了 readIndex 的日志，就可以查询状态机结果并返回 client 了。 优化后的线性一致性读也至少需要一轮 RPC（leader 确认心跳），并不比写操作快多少（最少也就一轮 RPC）。因为这轮读 RPC 仅仅是为了确认集群中没有新 leader 产生，那么如果 leader 上一次心跳发送的时间还不到选举超时时间下界，集群就不能选出一个新 leader，那么这段时间就可以不经过这轮心跳确认，直接返回读的结果。（不建议，因为时钟偏移、GC 等情况，通常认为时间不可靠） 如果不要求强一致性读，可以利用 follower 承载更大的读压力，类似数据库 follower 接受到读请求后，向 leader 请求 readIndex follower 等待自身状态机应用日志到 readIndex follower 查询状态机结果，并返回客户端 快速响应：最快的半数+1个节点响应即可 每个客户端应该维持一个 latestIdx 值，每个节点在接受读请求的时候与自己的 lastApplied 比较，如果这个值大于自己的 lastApplied，客户端重定向到一个 lastApplied 大于等于自己 latestIdx 的请求，并且每次读取请求都会返回这个节点的 lastApplied 值，客户端将 latestIdx 更新为此值，保持读取的线性一致性。 2.9 分析性能 Raft Evaluation 最基本的：每完成一个日志（命令）的复制与提交，需要的网络（RPC）来回次数。raft 在理想情况下，只需要一次 AppendEntries RPC 来回即可提交日志（理论上的极限）\n影响 Raft 性能的因素及优化方法\n生成快照：日志无限增长打满磁盘造成可用性问题 节点状态保存为 LSM Tree，存储最后应用日志的索引与任期，保证日志匹配特性 限定日志文件大小到达某一阈值后立即生成快照 使用写时复制，状态机的函数式顺序性天然支持 调节参数 心跳的随机时间，过快增加网络负载，过慢导致感知领导者崩溃的时间更长 选举的随机时间，如果大部分跟随者同时变为候选人则会导致选票被瓜分 流批结合 使用 Batch 能明显提升性能，如对于 RocksDB 的写，通常不会每次写入一个值，而是用 WriteBatch 缓存一批修改后整个写入，对于 Raft 来说，leader 可以一次收集多个 requests，一批发送给 follower（一个日志包含多个命令，然后批量复制，节省网络） 使用 Pipeline 让 leader 不用等待 follower 回复，继续给 follower 下一个日志。leader 维护一个 NextIndex 变量表示下一个给 follower 发送的 log 位置，只要 leader 和 follower 建立了连接，就可以认为网络稳定互通。所以当 leader 给 follower 发送了一批 log 后，可以直接更新 NextIndex，并立刻发送后面的 log，不需要等 follower 返回。如果网络出现了错误或者 follower 返回错误，就需要重新调整 NextIndex，重新发送 log。 并行追加 append log 涉及到落盘，有开销，完全可以在 leader 落盘的同时让 follower 尽快收到 log 并 append。如果一个 log 被大多数节点 append，就可以认为这个 log 被 committed 了，即时 leader 自己 append log 失败 panic 了，只要大多数 follower 能接受并成功 append，仍然可以认为这个 log 被 committed 了，后续就一定能 apply。 虽然 leader 能在 append log 之前给 follower 发 log，但是 follower 不能在 append log 之前告诉 leader 已经成功 append。。如果 follower 提前告知但后序实际失败，leader 仍然会认为这个 log 已经成功 committed，这样就有丢失数据的风险。 异步应用 asynchronous apply 被 committed 的 log 在什么时候被 apply 都不会影响数据的一致性，所以可以当一个 log 被 committed 之后，用另一个线程去异步 apply 这个 log。那么整个 raft 流程变为： leader 接受一个 client 发送的 request leader 将对应的 log 发送给其他 follower 并本地 append leader 继续接受其他 client 的 request，持续执行上一步 leader 发现 log 已经被 committed，在另一个线程 apply leader 异步 apply log 之后，返回结果给对应的 client 以上，完全并行处理 append log 和 apply log，对于多个 clients 来说，整体的并发量和吞吐上去了。 Multi-Raft：将数据分组，每组数据独立，用自己的 raft 来同步。 Raft 优化\nRaft 与 Paxos 比较 Paxos 实际上指一个能完美处理所有日志空洞带来的边界情况，并能保证处理这些边界情况的代价，要小于允许日志空洞带来的收益的共识算法。 raft 确实有不允许日志空洞这个性能上限，但大部分系统实现，连 raft 的上限都远远没有达到，所以无需考虑 raft 本身的瓶颈 raft 允许日志空洞的改造：Parallel Raft ","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/raft/","summary":"1. Introduction 为了便于理解，Raft 共识算法做了两件事 分成了三个子问题，便于理解上手 领导者选举 leader election 日志复制 log replication 安全性 safety 状态简化：对算法做出一些限制，减","title":"Raft 分布式共识算法"},{"content":"1. Introduction 论文：\nhttps://marcoserafini.github.io/papers/zab.pdf Zookeeper 是一个分布式应用程序协调服务，提供数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、master 选举、分布式锁、分布式队列等功能。其实现得益于类文件系统的数据模型和基于 Watcher 机制的分布式事件通知，以及自身的高容错数据一致性协议。\nZooKeeper 的一致性实际是处于强一致性和顺序一致性之间。因为客户读链接 ZooKeeper 集群后，所有的写操作都必须发送给集群唯一的 leader，这个 leader 在内部同步块中赋予每个写操作一个顺序序列号（内部称为zxid，是单调增加的），上一个写操作不commit，下一个写操作就不执行，这一点实际上已经实现了写入的强一致性（线性化）了。\n但 ZooKeeper 的读操作是不做线性化的，否则读取一定拿到最新数据的话，过于影响性能了。客户端会缓存自己见到的最大的 zxid，如果与任何 server 建立 session 时发现，这个 server 最近更新的数据比自己还旧，那 server 端是会拒绝建立 session 的。也就是说，客户端侧在任何情况下都不会得到更老的数据，这又实现了顺序一致性。\n2. ZAB 协议 ZAB 协议是为分布式协调服务 ZK 专门设计的一种支持崩溃恢复的原子广播协议，其借鉴了 Paxos 算法。\nZK 基于该协议采用了主备模型 leader \u0026amp; follower，来保证集群中各个副本之间数据一致性。在主备系统架构模型中，只有 leader 负责处理外部的写事务请求，leader 将数据同步到其他 follower 节点，follower 只在本地处理读请求，如果是写请求则向 leader 提交事务，leader 接收到事务后广播该事务，只要超过半数节点写入成功，该事务就会被提交。\nZAB 协议特点\n集群在半数一下节点宕机时仍对外提供正常服务 客户端写请求全部转交 leader 处理，leader 确保写变更能实时同步给所有 follower 及 observer leader宕机或整个集群重启时，需要确保已经在 leader 服务器上提交的事务最终被所有服务器提交，确保丢弃只在 leader 服务器上被提出的事务，并保证集群快速恢复到故障前状态 ZAB 协议包括两种基本模式：崩溃恢复和消息广播\n当整个集群启动过程中，或者当 leader 服务器出现网络中断、崩溃退出或重启等异常时，ZAB 进入崩溃恢复模式，选举产生新 leader 当选举产生了新的 leader，同时集群中有过半的机器与该 leader 服务器完成了状态同步后，ZAB 退出崩溃恢复模式，进入消息广播模式。 2.1 ZAB 流程协议 ZAB 协议流程在论文中具有4步，而zookeeper在实现中将理论压缩为三个步骤\n选举和发现 数据同步 原子广播 2.1.1 选举和发现 集群节点的状态有以下几种\nLOOKING: ZK 集群处于崩溃恢复状态的时候，各个节点处于 LOOKING 状态 LEADING: ZK 集群处于消息广播状态的时候，leader 节点处于 LEADING 状态 FOLLOWING: ZK 集群处于消息广播状态的时候，follower 节点处于 FOLLOWING 状态 选举阶段集群间互相传递消息称为投票，投票 Vote 主要包括两个维度的信息：ID、ZXID\nServerID：被推举的 leader 的服务器 ID，集群中每个 ZK 节点启动前要配置好这个全局唯一的 ID ZXID：被推举的 leader 的事务 ID，该值从当前节点中选取的已经提交过的最大的事务 ID 选举\n在初始阶段，每个服务都会处于 LOOKING 状态互相通信寻找 leader，找不到会投自己一票，选票包含（机器 server id，最近一次 commit 提交的 zxid），发给其他机器。 每台机器以(zxid、机器 id)的优先级，比对自己的选票和收到的选票，更新选票信息后再次发出。（拥有最大 ZXID 的节点会赢得选举，若一致则比较最大 Server ID） 统计投票，超过 quorum 数量，则声明或选， leader、follower 角色确立。 发现\n这个阶段的主要目的在于 leader 得到存活 follower 内存中的事务。follower 连接到\u0026quot;准 leader \u0026ldquo;，发送 ACKEPOCH，准 leader 收集 follower 发送的 zxid、sid，并且设定新的 epoch（原 epoch + 1），这样之前老的leader就无法再提交新的 proposals（提案）。 2.1.2 数据同步（数据恢复） leader向followers主动发起请求，这个阶段follower的数据要被同步为leader从上个阶段收集的数据。\nzookeeper leader存两个指标：\nminCommittedLog：leader内存中最小的提交日志 maxCommittedLog：leader数据库最大的提交日志 leader会结合指标根据每个learner数据状态发送不同的指令，可分为如下情况：\n回滚：learner数据比leader还新(\u0026gt;minCommittedLog)，leader要求learner回滚到同自己相同的水平 差异同步：learner数据过时但\u0026gt;=minCommittedLog，leader发送差异数据 回滚+差异同步：learner出现了上个epoch的数据（可能是上个朝代的leader） 快照全量同步：learner的数据比minCommittedLog小（非常古老了，必须用snapshot同步了） leader根据数据副本的不同的状态选择性的发送指令和数据，目的就是要让各个副本数据达成一致。 每个数据同步完毕的 learner 都会返回 ack 后，由 leader 将同步的 follower 加入到 forwardingFollowers 队列（hashSet）中，也就是说leader 维护了每个 learner 的 deadline time、socket对象、对应的阻塞队列（每个 learner 都有一个）等。\n不管 leader 还是 follower，启动都要经过以上阶段。同时节点任何步骤出现失败或超时，节点都会回退到选举阶段。\n2.1.3 原子广播 随着新的follower不断加入并同步好数据，leader判断可用节点达到quorum(一般是集群节点数量的一半加一)时，客户端发起的写入请求才会被这些参与同步的leader、learner接收*。\n原子广播类似两阶段提交，但是可以不收到全部 follower 反馈，只需要半数以上（避免严重阻塞）\n节点 A 接到任何客户端写入请求都要转发到 leader leader 生成 zxid，封装请求为 proposal 发给所有 followers 的 FIFO 队列（每个 follower 都有一个 FIFO 队列） follower 接到后 proposal，先写 transactionlog 事务日志到磁盘，然后回复 leader ack（3.7.0版本此处新增了异步发送特性）。 leader 接到半数以上 ack 后认为消息发送成功，再向所有 follower 发 commit、所有 observer 发 proposal，同时自身完成事务提交。leader先判断上个zxid是否还存在，只有不存在才继续，之后再判断是否达到半数以上 ack，判断半数以上 ack 有两种实现，一种是分组得分制（QuorumHierarchical）、一种是 ack 计数制。 follower 接到并执行 commit 后回复 leader ack，这里有一点，如果提交的 zxid 不是 follower 最近 pending 的那个（存储于 pendingTxns），也就是可能网络丢包或绕路了，那 follower 直接退出。 节点A执行后，向客户端返回 response 2.2 ZAB 故障检测（心跳机制） 发现、同步和广播阶段都没有考虑节点宕机的问题，为了检测失败，Zab 提供 followers 和 leader间的周期性心跳\n如果 leader 在一段时间内没有收到 quorum 数量的心跳，它则放弃领导权并进入选举。 如果 follower 在一段时间没有接到 leader 的心跳，会进入选举状态。 也就是说，维持主从关心的心跳。是由 leader 主动 ping 的 当 follower 处理的时候，是直接返回的。\nleader 对于 ping 包的构造，主要就是会携带最近发起过 proposal 的 txid，其他不带有任何数据。\n同时这两种情况都会使集群进入恢复模式。\n2.3 ZAB 崩溃恢复 在zab协议的第一个阶段（选举和发现）中，内含了崩溃恢复的机制，恢复阶段从 ZAB 协议的\u0026quot;同步\u0026quot;阶段中集成了很多内容。\n崩溃恢复的意义就是追求数据一致性，它保证：\nleader 发出过 commit 的消息，最终会被所有节点 commit leader 没 commit 的消息会被丢弃 2.4 ZAB 提交提案 原子广播 2PC 中，第一步 leader 会发送 proposal 到 follower，半数节点以上 ack 才进行 commit，如果没有半数节点 ack呢？或者半数以上节点拒绝了呢？传统数据库 2PC 会进行回滚，ZooKeeper 的话，leade r会下台，如果选举后新的 leader 内存中存在这个未 commit 的 proposal，才会再次尝试提交。\n如果 follower 没有接到 COMMIT，有三个机制保证数据最终一致：\n下次事务请求时，leader 会向待同步节点发送 SYNC 命令 follower 接到一个新包发现跳包了，自行推出，后面重连到集群 如果真的发生网络分区了，leader 会将这个长久不联系的节点从可用节点剔除 3 ZAB 存在的问题 客户端看到的不一致 以为在广播 commit 阶段，leader 和 follower 之间有网络延迟，到达 follower 时先后时间点不一致，注定了有些 follower 比其他更快的读取到最新的数据 一个 client 两个连接，造成的消息不守序 在一个 client 端建立一条跟 ZK 的连接时，消息按严格有序的方式投递到 leader，并严格的顺序被广播给 follower。但是如果一个客户端机器建立两个连接时，发送给两个连接的消息是不能保序的。 重复消息投递的可能性 如果一个 proposal 在 leader 宕机前没有被 commit，而且接收到 proposal 的 follower 也不确定是哪几台，那么新的 leader 选举时，包含新 proposal 日志的 server 不一定参与集群选举，如果参与的话，该日志会最终被 zk 集群 commit，如果没参与，那该事务就丢失了。虽然两种情况 client 端确定本次请求失败，但是前者在 server 确实被记录了，如果 client 认为失败而补发，那请求会被重复投递。 ","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/zab/","summary":"1. Introduction 论文： https://marcoserafini.github.io/papers/zab.pdf Zookeeper 是一个分布式应用程序协调服务，提供数据发布/订阅、负载均衡、命名服务、分布式协调/通知、集群管理、master 选举、分布式锁、","title":"ZAB 原子广播协议"},{"content":"1. 事务与分布式事务 1.1 事务 事务是数据库管理系统执行过程中的一个逻辑单元，能够保证一个事务中所有操作要么全部执行，要么全不执行。\n数据库事务拥有四个特性 ACID，分别为 Atomicity 原子性、Consistency 一致性、Isolation 隔离性、Durability 持久性。\n1.2 分布式事务 分布式事务指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点上。一个流程操作不取决于本地的数据库操作。分布式事务就是为了保证不同数据库的一致性。\n分布式事务之所以复杂，一个主要原因是同一个事务之间的执行多段代码会因为网络的不稳定造成失败等问题。当通过网络请求其他服务的接口时，可能得到 正确、失败、超时 三种结果。无论成功或失败都能得到唯一确定的结果，但是超时却不能确定接收者是否成功处理了请求，而这也成为造成诸多问题的诱因。系统之间的通信可靠性从单一系统中的可靠变成了微服务结构之间的不可靠，分布式事务其实就是在不可靠的通信下实现事务的特性。\n1.3 分布式事务基础：一致性 强一致性\n任何一次都能读到某个数据的最近一次写数据。系统中的所有进程，看到的操作顺序，都和全局时钟下的顺序一致。任意时刻，所有节点中的数据都是一样的。 弱一致性\n数据更新后，如果能容忍后序的访问只能访问到部分或者全部访问不到，则是弱一致性。 最终一致性\n不保证在任意时刻任意节点上的同一份数据都相同的，但是随着时间的推移，不同节点上的同一份数据总是在向趋同的方向变化。一段时间后，节点间的数据会最终达到一致状态。 1.4 分布式事务基础：CAP 原则 CAP 原则又称为 CAP 定理，指在一个分布式系统中，Consistency 一致性、Availability 可用性、Partition-tolerance 分区容错性 三者不可兼得。\nConsistency 一致性：在分布式系统中的所有数据备份，在同一时刻是否同样的值（等同于所有节点访问同一份最新的数据副本） Availability 可用性：在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求（对数据更新具备高可用性） Partition-tolerance 分区容错性：以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。 CAP 三者取舍\nCA：优先保证一致性和可用性，放弃系统扩展性，系统不再是分布式 CP：优先保证一致性和分区容错性，在一致性要求较高的场合比较常见 Zookeeper，HBase；一旦发生网络故障或消息丢失，会牺牲用户体验，恢复后才逐渐能访问 AP：优先保证可用性和分区容错性，如 RocketMQ 的 那么server，SpringCloud 的 Eureka 分布式事务会部分遵循 ACID 规范\n原子性：严格遵循 一致性：事务完成后的一致性严格遵循；事务中的一致性可适当放宽 隔离性：并行事务间不可影响；事务中间结果可见性允许安全放宽 持久性：严格遵循 因为事务过程中，不是一致的，但事务会最终完成，最终达到一致，所以我们把分布式事务称为“最终一致”\n1.5 分布式事务基础：BASE 理论 BASE aka Basically Availability Soft State Eventual Consistency\nBasically Availability 基本可用：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用 Soft State 软状态：允许系统存在中间状态，而该中间状态不会影响系统整体可用性 Eventual Consistency 最终一致性：系统中的所有数据副本经过一定时间后，最终能够达到一致的状态 BASE 理论本质上是对 CAP 理论的延伸，是对 AP 方案的一个补充\n1.6 CP + HA 分布式事务是在分布式环境下，遵循CAP理论，在CAP三者中只能够三选二，那么分布式事务是那种的组合呢？分布式事务是CP+HA，其中A是没有完全符合，但是能够达到Highly-Available，即高可用。\n近些年分布式理论进一步发展，产生了Paxos、Raft等CP的协议，在这基础上，加上硬件稳定性升级，可以在保证CP的情况下，做到高可用。谷歌分布式锁Chubby的公开数据显示，集群能提供99.99958％的平均可用性，一年也就130s的运行中断，已经能够满足非常严苛的应用要求。现在的SQL类数据库软件，都是走CP+HA，只是HA会比谷歌的这个极致数据更低一些，但一般都能够达到4个9\nCP+HA意味着不是BASE，意味着你只要写入成功，那么接下来的读，能够读取到最新的结果，开发人员不用担心读取到的不是最新数据，在多副本读写上面，与单机是一致的。\n2. 分布式事务解决方案 2.1 XA (2PC) XA 规范是 X/Open 组织定义的分布式事务处理 Distributed Transaction Processing 标准。XA 事务由一个或多个资源管理器（RM）、一个事务管理器（TM）和一个应用程序（ApplicationProgram）组成。\nXA 规范描述了全局的事务管理器与局部的资源管理器之间的接口。XA 规范的目的是允许的多个资源（数据库、应用服务器、消息队列等）在同一事务中访问，这样可以使 ACID 属性跨越应用程序而保持有效。XA 规范主要定义了(全局)事务管理器(TM)和(局部)资源管理器(RM)之间的接口。本地的数据库如 mysql 在 XA 中扮演的是 RM 角色。\nXA 规范使用两阶段提交（2PC Two-Phase Commit）来保证所有资源同时提交或回滚任何特定的事务。\nXA 流程\n阶段一 Prepare：提交事务请求 事务询问：事务管理器向所有本地资源管理器发送请求，询问是否可以执行事务提交操作 执行事务：参与者节点执行询问发起为止的所有事务操作，并将 undo 信息和 redo 信息写入日志（若成功这里其实每个参与者已经执行了事务的操作，执行过程中会锁住资源，日志用于回滚） 所有参与者都将本事务是否成功的信息反馈发给管理者。参与者事务操作实际执行成功，返回确认，否则返回失败。 阶段二 Commit / Rollback：当事务管理者(TM)确认所有参与者(RM)都 ready 后，最终决定是否可以执行事务提交。事务管理器根据所有本地资源管理器的反馈，通知所有本地资源管理器，步调一致地在所有分支上提交或者回滚。 同意提交 管理者向所有参与者发出正式提交 commit 请求 参与者正式完成操作，释放在整个事务期间内占用的资源 参与者节点向管理者节点发送完成 管理者节点收到所有参与者节点的完成消息后，完成事务 终止提交 管理者向所有参与者发出回滚 rollback 请求 参与者节点利用之前写入的 undo 信息进行回滚，并释放在整个事务期间内占用的资源 参与者节点向管理者节点发送回滚完成消息 管理者节点收到所有参与者节点反馈的回滚完成后，取消事务 目前主流的数据库基本都支持XA事务，包括mysql、oracle、sqlserver、postgre。\n优点\n对业务侵⼊很小，它最⼤的优势就是对使⽤⽅透明，用户可以像使⽤本地事务⼀样使⽤基于 XA 协议的分布式事务，能够严格保障事务 ACID 特性。 缺点\n同步阻塞：当参与事务者存在占用公共资源的情况，其中一个占用了资源，其他事务参与者就只能阻塞等待资源释放，处于阻塞状态。对资源进行了长时间的锁定，并发度低。 单点故障：一旦事务管理器出现故障，整个系统不可用 数据不一致：在阶段二，如果事务管理器只发送了部分 commit 消息，此时网络发生异常，那么只有部分参与者接收到 commit 消息，也就是说只有部分参与者提交了事务，使得系统数据不一致。 不确定性：当协事务管理器发送 commit 之后，并且此时只有一个参与者收到了 commit，那么当该参与者与事务管理器同时宕机之后，重新选举的事务管理器无法确定该条消息是否提交成功。 XA要求数据库本身提供对规范和协议的支持 扩展：3PC\nCanCommit - PreCommit - DoCommit 降低参与者的阻塞范围，并且能够在单点故障后继续达成一致 第二阶段时若出现网络分区，导致有些节点提交不提交事务，会造成事务不一致 2.2 AT AT 对业务代码完全无侵入性，使用非常简单，改造成本低。我们只需要关注自己的业务SQL，AT模式下框架会通过分析我们业务SQL，反向生成回滚数据。\nAT 包含两个阶段\n一阶段，所有参与事务的分支，本地事务Commit 业务数据和回滚日志（undoLog） 二阶段，事务协调者根据所有分支的情况，决定本次全局事务是Commit 还是 Rollback（二阶段是完全异步） 核心流程\n为每个事务参与者的数据库创建一个 undo log 表，用于记录 DML SQL 执行前的行记录 每个事务参与者实际执行 DML SQL 时，生成修改前数据插入到 undo log 表中 流程图\n拓扑图\n优点\n该事务模式使用方式，类似XA模式，业务无需编写各类补偿操作，回滚由框架自动完成 缺点\n也类似XA，存在较长时间的锁，不满足高并发的场景。从性能的角度看，AT模式会比XA更高一些，但也带来了脏回滚这样的新问题。 2.3 TCC TCC 完整语义 Try-Confirm-Cancel\nTry：尝试执行，完成所有业务检查（一致性），预留必须业务资源（准隔离性），如加锁，加标记字段。TCC事务机制中的业务逻辑（Try），从执行阶段来看，与传统事务机制中业务逻辑相同。但从业务角度来看，却不一样。TCC机制中的Try仅是一个初步操作，它和后续的确认一起才能真正构成一个完整的业务逻辑。TCC机制将传统事务机制中的业务逻辑一分为二，拆分后保留的部分即为初步操作（Try）；而分离出的部分即为确认操作（Confirm），被延迟到事务提交阶段执行。TCC事务机制以初步操作（Try）为中心的，确认操作（Confirm）和取消操作（Cancel）都是围绕初步操作（Try）而展开。因此，Try阶段中的操作，其保障性是最好的，即使失败，仍然有取消操作（Cancel）可以将其不良影响进行回撤。可以认为 1 [传统事务机制]的业务逻辑 = [TCC事务机制]的初步操作（Try） + [TCC事务机制]的确认逻辑（Confirm）。 Confirm：真正确认执行业务，不做任务业务检查，只用 Try 阶段预留的业务资源；操作必须满足幂等性，失败后需要进行重试。确认操作（Confirm）是对初步操作（Try）的一个补充。当TCC事务管理器决定commit全局事务时，就会逐个执行初步操作（Try）指定的确认操作（Confirm），将初步操作（Try）未完成的事项最终完成。 Cancel：取消执行，释放 Try 阶段预留的业务资源；操作必须满足幂等性，异常处理和 Confirm 一致。取消操作（Cancel）是对初步操作（Try）的一个回撤。当TCC事务管理器决定rollback全局事务时，就会逐个执行初步操作（Try）指定的取消操作（Cancel），将初步操作（Try）已完成的事项全部撤回。 在 Try 阶段，对业务系统进行检查及资源预览，比如订单和存储操作，需要检查库存剩余数量是否够用，并进行预留，预留操作的话就是新建一个可用库存数量字段，Try 阶段操作是对这个可用库存数量进行操作。\n基于 TCC 实现分布式事务，会将原来只需要一个接口就可以实现的逻辑拆分为 Try、Confirm、Cancel 三个接口，所以代码实现复杂度相对较高，对业务的侵入性大。\nTCC的Confirm/Cancel阶段在业务逻辑上是不允许返回失败的，如果因为网络或者其他临时故障，导致不能返回成功，TM会不断的重试，直到Confirm/Cancel返回成功。\nTCC特点如下\n并发度较高，无长期资源锁定。 开发量较大，需要提供Try/Confirm/Cancel接口。 一致性较好，不会发生SAGA已扣款最后又转账失败的情况 TCC适用于订单类业务，对中间状态有约束的业务 TCC 和 2PC？ TCC 并不是 2PC 的一种。2PC 需要 RM 提供底层支持（一般是兼容 XA），而 TCC 不需要。对于传统事务机制 X/Open XA 2PC，其特征在于它不依赖资源管理器 Resource Manager 对 XA 的支持，而是通过对（由业务系统提供的）业务逻辑的调度来实现分布式事务。\n对于业务系统中一个特定的业务逻辑S，其对外提供服务时，必须接受一些不确定性，即对业务逻辑执行的一次调用仅是一个临时性操作，调用它的消费方服务M保留了后续的取消权。如果M认为全局事务应该rollback，它会要求取消之前的临时性操作，这将对应S的一个取消操作；而当M认为全局事务应该commit时，它会放弃之前临时性操作的取消权，这对应S的一个确认操作。\n每一个初步操作，最终都会被确认或取消。因此，针对一个具体的业务服务，TCC事务机制需要业务系统提供三段业务逻辑：初步操作Try、确认操作Confirm、取消操作Cancel。\nTCC 在事务处理上，要么调用 confirm，要么调用 cancel；try 逻辑与全局事务无关。 使用 2PC 时完整的事务生命周期是：begin -\u0026gt; 业务逻辑 -\u0026gt; prepare -\u0026gt; commit 使用 TCC 时完整的事务生命周期是：begin -\u0026gt; 业务逻辑 (try) -\u0026gt; commit (confirm 业务)\n在执行阶段可以将二者一一对应\n2PC 业务阶段 - TCC try 业务阶段 2PC 提交阶段 (prepare \u0026amp; commit) - TCC confirm 提交阶段 2PC 回滚阶段 (rollback) - TCC cancel 回滚阶段 TCC 不是 2PC，只是它对事务的 提交/回滚 是通过执行一段 confirm/cancel 业务逻辑来实现而已。\nTCC 事务管理器协调者设计 TCC全局事务必须基于 RM 本地事务来实现全局事务\nTry/Confirm/Cancel业务在执行时，会访问资源管理器（Resource Manager，下文简称RM）来存取数据。这些存取操作，必须要参与RM本地事务，以使其更改的数据要么都commit，要么都rollback。 分布式事务管理框架的职责，不是做出全局事务提交/回滚的指令，而是管理全局事务提交/回滚的过程。 实际实现中：\n只实现 try cancel 就是一个 SAGA 一般扣除类动作，try 时即扣除，cancel 时补偿，confirm 为空；因为 confirm 时再完成扣除可能已经余额不足，因此要求 confirm 一定成功。 但是发放类动作，一般不适用 SAGA，因为 cancel 前可能已经被消耗，导致无法回滚，此时必须用 TCC 语义在 confirm 时是肌肤放。 只实现 try confirm 就是一个 XA TCC 语义与问题解决 子事务接口约束\n中间态设计：try 成功后，confirm / cancel 必须成功 confirm / cancel 接口必须保持幂等性，防止一次请求多次操作 cancel 允许空回滚 cancel 允许请求倒挂（try 悬挂） 问题：Try 超时（空回滚）\nCancel 接口设计时允许空回滚。在 try 接口因为丢包没有收到时，事务管理器会触发回滚，这时会出发 Cancel 接口，若发现没有对应事务的 xid 或主键时，需要返回回滚成功。让事务服务管理器认为已回滚，否则会不断重试。或直接存储 try 失败的事务 xid。 问题：Confirm / Cancel 超时\n因为网络抖动或拥堵可能超时，事务管理器会对资源进行重试操作，为了不因为重复调用而多次占用资源，设计时进行幂等控制。 问题：Try 比 Cancel 晚到达（try 悬挂）\nCancel 比 try 先执行，事务管理器生成回滚，而之后收到了 try 接口调用。此时 try 接口因 cancel 已执行而不再执行，否则产生数据不一致。所以在 try 前先检查该事务 xid 或业务主键，如果已经标记为回滚成功过，就不再执行 try 的业务操作。 2.4 SAGA SAGA事务，其核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。每个参与者都定义一个正向行为（变更）和一个反向行为（补偿），分布式事务按照既定顺序执行正向行为直到全部成功（提交），如果中间发生错误，则逆序执行对应的反向行为（回滚）。\nSAGA 的补偿按照拓扑逆序补偿， 但是是一种不完全补偿，因为每个本地事务都已经提交，所以无法保证每个事务都能被回滚，可能发生服务器宕机，网络失败等问题，最后需要人工干预回退。 SAGA 执行流程如下\n分支事务 1 到 N 依次执行成功，全局事务成功 分支事务 i 执行失败，从分支事务 i 倒序至分支事务 1，依次执行补偿，失败则重试，补偿需幂等（回滚优先策略） 分支事务 i 执行失败，重试直到成功，然后依次执行后序分支事务，正向操作保障幂等（重试优先策略） 适用场景\n业务流程长、业务流程多 长事务适用，对中间结果不敏感的业务场景适用 参与者包含其它公司或遗留系统服务，无法提供 TCC 模式要求的三个接口 优势\n并发度高，不用像XA事务那样长期锁定资源 一阶段提交本地事务，无锁，高性能 事件驱动架构，参与者可异步执行，高吞吐 需要定义正常操作以及补偿操作，开发量比XA大，但是补偿服务易于实现 相较于 TCC 业务侵入度适中 缺点\n不保证隔离性 一致性较弱，对于转账，可能发生A用户已扣款，最后转账又失败的情况 2.5 本地消息表 本地消息表方案中会有消息生产者与消费者两个角色，假设服务 A 是消息的生产者，服务 B 是消息的消费者。写本地消息和业务操作放在一个事务里，保证了业务和发消息的原子性，要么他们全都成功，要么全都失败。此方案的核心是将需要分布式处理的任务通过消息日志的方式来异步执行。消息日志可以存储到本地文本、数据库或消息队列，再通过业务规则自动或人工发起重试。人工重试更多的是应用于支付场景，通过对账系统对事后问题的处理。\n当服务 A 被其他服务调用发生数据库表更操作，首先会更新该服务数据库的业务表，其次会往相同数据库的消息表中插入一条数据，两个操作发生在同一个事务中 服务 A 的脚本定期轮询本地消息往 mq 中写入一条消息，如果消息发送失败会进行重试 服务 B 消费 mq 中的消息，并处理业务逻辑。如果本地事务处理失败，会在继续消费 mq 中的消息进行重试，如果业务上的失败，可以通知服务 A 进行回滚操作，或进行告警通知相关人员进行处理。 本地消息表的实现条件\n消费者与生成者的接口都要幂等 生产者需要额外的创建消息记录表 可能需要提供补偿逻辑，如果消费者业务失败，生产者可支持回滚操作 进行重试或进行业务逻辑告警，通过人工介入的方式处理。 适用场景\n可异步执行的业务，且后续操作无需回滚的业务 容错机制\n扣减余额事务 失败时，事务直接回滚，无后续步骤 轮序生产消息失败， 增加余额事务失败都会进行重试 本地消息表的特点\n不支持回滚 轮询生产消息难实现，如果定时轮询会延长事务总时长，如果订阅 binlog 则开发维护困难 适用于可异步执行的业务，且后续操作无需回滚的业务 2.6 事务消息 在上述的本地消息表方案中，生产者需要额外创建消息表，还需要对本地消息表进行轮询，业务负担较重。阿里开源的RocketMQ 4.3之后的版本正式支持事务消息，该事务消息本质上是把本地消息表放到RocketMQ上，解决生产端的消息发送与本地事务执行的原子性问题。\n事务消息发送及提交\n发送消息（half消息） 服务端存储消息，并响应消息的写入结果 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行） 根据本地事务状态执行Commit或者Rollback（Commit操作发布消息，消息对消费者可见） 补偿流程\n对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查” Producer收到回查消息，返回消息对应的本地事务的状态，为Commit或者Rollback 事务消息方案与本地消息表机制非常类似，区别主要在于原先相关的本地表操作替换成了一个反查接口 事务消息特点\n长事务仅需要分拆成多个任务，并提供一个反查接口，使用简单 事务消息的回查没有好的方案，极端情况可能出现数据错误 适用于可异步执行的业务，且后续操作无需回滚的业务 适用场景\n可异步执行的业务，且后续操作无需回滚的业务 2.7 最大努力通知 发起通知方通过一定的机制最大努力将业务处理结果通知到接收方。具体包括：\n有一定的消息重复通知机制。因为接收通知方可能没有接收到通知，此时要有一定的机制对消息重复通知。 消息校对机制。如果尽最大努力也没有通知到接收方，或者接收方消费消息后要再次消费，此时可由接收方主动向通知方查询消息信息来满足需求。 前面的本地消息表和事务消息都属于可靠消息，与这里的最大努力通知有什么不同？\n可靠消息一致性，发起通知方需要保证将消息发出去，并且将消息发到接收通知方，消息的可靠性关键由发起通知方来保证。 最大努力通知，发起通知方尽最大的努力将业务处理结果通知为接收通知方，但是可能消息接收不到，此时需要接收通知方主动调用发起通知方的接口查询业务处理结果，通知的可靠性关键在接收通知方。 解决方案上，最大努力通知需要：\n提供接口，让接受通知放能够通过接口查询业务处理结果 消息队列ACK机制，消息队列按照间隔1min、5min、10min、30min、1h、2h、5h、10h的方式，逐步拉大通知间隔 ，直到达到通知要求的时间窗口上限。之后不再通知 适用类型\n业务通知类型，例如微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口 2.8 分布式事务解决方案总结 解决方案 流程 优点 缺点 适用场景 XA 一阶段尝试并写入 undo log，二阶段根据反馈提交或回滚 原理简单，实现方便 1. 同步阻塞，所有节点都事务阻塞，包括第三方公共资源\n2. 单点故障，管理者故障则参与者持续锁定\n3. 数据不一致，二阶段部分 commit\n4. 不确定性，宕机后重选管理器无法确定是否提交成功\n5. 要求数据库本身提供对规范和协议的支持 AT AT模式下框架会通过分析我们业务SQL，反向生成回滚数据 类似 XA，业务无需编写各类补偿操作，回滚由框架自动完成 类似XA，存在较长时间的锁，不满足高并发的场景。从性能的角度看，AT模式会比XA更高一些，但也带来了脏回滚这样的新问题。 TCC 预留资源 - 提交 - 取消 1. 高并发，无长期资源锁定\n2. 一致性较好，不会发生 SAGA 已扣款又转账失败情况\n3. 不需要存储层像 XA 一样天然支持 1. 开发量大，需要提供幂等 Try-Confirm-Cancel 接口\n2. 业务侵入性大\n3. 实现复杂，需要处理好悬挂和空回滚 订单类业务等对中间状态有约束的业务 SAGA 定义正向进行和反向补偿，失败逆序补偿 1. 高并发，无长期资源锁定\n2. 一阶段提交本地事务，无锁高性能\n3. 事件驱动架构，参与者可异步执行，高吞吐\n4. 补偿服务容易实现\n5. 相较于 TCC 业务侵入度适中 1. 需要定义正向和补偿操作，开发量比 XA 大\n2. 不保证隔离性\n3. 一致性较弱，对于转账会发生用户已扣款最后又失败的情况 1. 业务流程长、业务流程多\n2. 长事务，对中间结果不敏感\n3. 参与者包含其他遗留服务，无法提供 TCC 要求的三接口 本地消息表 将需要分布式处理的任务通过消息日志的方式来异步执行 不支持回滚 可异步执行的任务，且后序操作无需回滚的业务，如支付场景（可以根据对账系统人工重试） 事务消息 把本地消息表放到RocketMQ上，解决生产端的消息发送与本地事务执行的原子性问题 长事务仅需要分拆成多个任务，并提供一个反查接口，使用简单 可异步执行的业务，且后续操作无需回滚的业务 最大努力通知 发起通知方通过一定的机制最大努力将业务处理结果通知到接收方，包括消息重复通知、消息校对 业务通知类型，例如微信交易的结果，就是通过最大努力通知方式通知各个商户，既有回调通知，也有交易查询接口 ","permalink":"https://blog.hypertars.com/posts/developer/distributed_systems/transaction/","summary":"1. 事务与分布式事务 1.1 事务 事务是数据库管理系统执行过程中的一个逻辑单元，能够保证一个事务中所有操作要么全部执行，要么全不执行。 数据库事务拥有四","title":"分布式事务"}]